#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç²¾ç»†åŒ–Monkeyæ—¥å¿—æ ¹å› åˆ†æå·¥å…· - åˆ—è¡¨å¼æŠ¥å‘Šè¾“å‡º
åŠŸèƒ½ï¼šæä¾›ä»£ç çº§å®šä½å’Œå…·ä½“é—®é¢˜åˆ†ç±»ï¼Œä»¥æ¸…æ™°åˆ—è¡¨å½¢å¼å‘ˆç°
"""

import re
import os
import sys
import json
import hashlib
import subprocess
from datetime import datetime
from collections import defaultdict, Counter
import argparse

# ========================================
# Windows GBKç¼–ç å…¼å®¹å¤„ç†
# ========================================

def safe_print(text, **kwargs):
    """å®‰å…¨æ‰“å°å‡½æ•°ï¼Œå¤„ç†Windows GBKç¼–ç é—®é¢˜"""
    try:
        print(text, **kwargs)
    except UnicodeEncodeError:
        # ç§»é™¤emojiå’Œç‰¹æ®Šå­—ç¬¦
        safe_text = text.encode('gbk', errors='ignore').decode('gbk')
        print(safe_text, **kwargs)

def get_emoji(emoji_char, fallback=''):
    """è·å–emojiå­—ç¬¦ï¼ŒWindows GBKç¯å¢ƒè¿”å›fallback"""
    try:
        # æµ‹è¯•æ˜¯å¦èƒ½ç¼–ç 
        emoji_char.encode(sys.stdout.encoding or 'utf-8')
        return emoji_char
    except (UnicodeEncodeError, AttributeError):
        return fallback

# Emojiæ˜ å°„ï¼ˆWindowså…¼å®¹ï¼‰
EMOJI = {
    'check': get_emoji('âœ…', '[OK]'),
    'cross': get_emoji('âŒ', '[X]'),
    'warning': get_emoji('âš ï¸', '[!]'),
    'folder': get_emoji('ğŸ“', '[DIR]'),
    'file': get_emoji('ğŸ“‚', '[FILE]'),
    'search': get_emoji('ğŸ”', '[SEARCH]'),
    'save': get_emoji('ğŸ’¾', '[SAVE]'),
    'process': get_emoji('ğŸ”„', '[PROC]'),
    'clock': get_emoji('â±ï¸', '[TIME]'),
    'target': get_emoji('ğŸ¯', '[TARGET]'),
    'note': get_emoji('ğŸ“', '[NOTE]'),
    'chart': get_emoji('ğŸ“Š', '[CHART]'),
    'red_circle': get_emoji('ğŸ”´', '[CRASH]'),
    'yellow_circle': get_emoji('ğŸŸ¡', '[ANR]'),
    'orange_circle': get_emoji('ğŸŸ ', '[EXCEPTION]'),
    'clipboard': get_emoji('ğŸ“‹', '[REPORT]'),
    'phone': get_emoji('ğŸ“±', '[DEVICE]'),
    'blue_circle': get_emoji('ğŸ”µ', '[MEDIUM]'),
    'green_circle': get_emoji('ğŸŸ¢', '[LOW]'),
    'star': get_emoji('ğŸŒŸ', '[EXCELLENT]'),
    'thumbs_up': get_emoji('ğŸ‘', '[GOOD]'),
    'bulb': get_emoji('ğŸ’¡', '[TIP]'),
}

class ListStyleMonkeyAnalyzer:
    def __init__(self, target_package=None):
        self.target_package = target_package
        self.monkey_log = []
        self.log_file_path = None  # ä¿å­˜Monkeyæ—¥å¿—æ–‡ä»¶è·¯å¾„
        self.logcat_dir_path = None  # ä¿å­˜å¯¹åº”çš„Logcatç›®å½•è·¯å¾„
        self.analysis_results = {
            'crashes': [],
            'anrs': [],
            'exceptions': [],
            'performance_issues': [],
            'test_summary': {},
            'code_level_issues': defaultdict(list),
            'component_issues': defaultdict(list)
        }
        # Monkeyè‡ªèº«ç›¸å…³çš„åŒ…å/è¿›ç¨‹åï¼Œéœ€è¦è¿‡æ»¤
        self.monkey_internal_patterns = [
            'flipjava.io',
            'com.android.commands.monkey',
            'android.app.Instrumentation',
            '/system/bin/monkey',
            'MonkeySourceNetwork',
            'MonkeySourceRandom'
        ]

    def load_monkey_log(self, file_path):
        """åŠ è½½Monkeyæ—¥å¿—æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                self.monkey_log = f.readlines()
            
            # ä¿å­˜æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼‰
            self.log_file_path = os.path.abspath(file_path)
            
            # å°è¯•æ‰¾åˆ°å¯¹åº”çš„ logcat_logs ç›®å½•
            # å¦‚æœæ—¥å¿—æ–‡ä»¶åœ¨ monkey_logs_xxx ç›®å½•ä¸­ï¼ŒæŸ¥æ‰¾å¯¹åº”çš„ logcat_logs_xxx ç›®å½•
            file_dir = os.path.dirname(self.log_file_path)
            dir_name = os.path.basename(file_dir)
            
            if dir_name.startswith('monkey_logs_'):
                # æå–æ—¶é—´æˆ³
                timestamp = dir_name.replace('monkey_logs_', '')
                # æ„å»ºå¯¹åº”çš„ logcat_logs ç›®å½•è·¯å¾„
                parent_dir = os.path.dirname(file_dir)
                logcat_dir = os.path.join(parent_dir, f'logcat_logs_{timestamp}')
                
                # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
                if os.path.exists(logcat_dir) and os.path.isdir(logcat_dir):
                    self.logcat_dir_path = logcat_dir
                    safe_print(f"{EMOJI['check']} æ‰¾åˆ°å¯¹åº”çš„ Logcat ç›®å½•: {logcat_dir}")
                else:
                    self.logcat_dir_path = None
            else:
                self.logcat_dir_path = None
            
            safe_print(f"{EMOJI['check']} å·²åŠ è½½Monkeyæ—¥å¿—: {file_path} ({len(self.monkey_log)} è¡Œ)")
            return True
        except Exception as e:
            safe_print(f"{EMOJI['cross']} åŠ è½½Monkeyæ—¥å¿—å¤±è´¥: {e}")
            return False
    
    def _is_monkey_internal_error(self, process_name, context=""):
        """åˆ¤æ–­æ˜¯å¦æ˜¯Monkeyå·¥å…·è‡ªèº«çš„é”™è¯¯
        
        Args:
            process_name: è¿›ç¨‹å
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå †æ ˆã€é”™è¯¯è¯¦æƒ…ç­‰ï¼‰
            
        Returns:
            bool: Trueè¡¨ç¤ºæ˜¯Monkeyè‡ªèº«é”™è¯¯ï¼Œåº”è¯¥è¿‡æ»¤æ‰
        """
        # æ£€æŸ¥è¿›ç¨‹å
        if process_name:
            for pattern in self.monkey_internal_patterns:
                if pattern in process_name:
                    return True
        
        # æ£€æŸ¥ä¸Šä¸‹æ–‡
        if context:
            for pattern in self.monkey_internal_patterns:
                if pattern in context:
                    return True
        
        return False
    
    # ==================== å¢å¼ºåŠŸèƒ½ï¼šæ™ºèƒ½é”™è¯¯å»é‡ ====================
    
    def _calculate_stack_signature(self, error):
        """è®¡ç®—é”™è¯¯çš„å †æ ˆç­¾åï¼Œç”¨äºå»é‡
        
        ç­¾åç»„æˆï¼šå¼‚å¸¸ç±»å‹ + å…³é”®è°ƒç”¨æ–¹æ³•ï¼ˆå‰3ä¸ªï¼‰+ è¿›ç¨‹å
        """
        context = ' '.join(error.get('context', []))
        
        # æå–å¼‚å¸¸ç±»å‹
        exception_pattern = r'(\w+Exception|\w+Error)'
        exceptions = re.findall(exception_pattern, context)
        exception_type = exceptions[0] if exceptions else 'Unknown'
        
        # æå–è°ƒç”¨æ ˆä¸­çš„å…³é”®æ–¹æ³•ï¼ˆå‰3ä¸ªï¼‰
        method_pattern = r'at ([\w\.$]+\.[\w]+)\('
        methods = re.findall(method_pattern, context)
        key_methods = methods[:3] if methods else []
        
        # ç»„åˆç­¾å
        signature_parts = [
            exception_type,
            error.get('processName', ''),
            *key_methods
        ]
        
        signature = '|'.join(signature_parts)
        return hashlib.md5(signature.encode()).hexdigest()[:16]
    
    def deduplicate_errors(self, errors):
        """å¯¹é”™è¯¯è¿›è¡Œå»é‡å¹¶ç»Ÿè®¡"""
        error_groups = defaultdict(lambda: {
            'error': None,
            'count': 0,
            'timestamps': [],
            'first_seen': None,
            'last_seen': None
        })
        
        for error in errors:
            signature = self._calculate_stack_signature(error)
            group = error_groups[signature]
            
            if group['error'] is None:
                group['error'] = error
                group['first_seen'] = error.get('timestamp')
            
            group['count'] += 1
            group['timestamps'].append(error.get('timestamp'))
            group['last_seen'] = error.get('timestamp')
        
        # æ„å»ºå»é‡åçš„ç»“æœ
        deduplicated = []
        for signature, group in error_groups.items():
            error = group['error'].copy()
            error['deduplication'] = {
                'signature': signature,
                'occurrences': group['count'],
                'first_seen': group['first_seen'],
                'last_seen': group['last_seen'],
                'frequency': self._calculate_frequency(group['timestamps'])
            }
            deduplicated.append(error)
        
        # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åº
        deduplicated.sort(key=lambda x: x['deduplication']['occurrences'], reverse=True)
        
        return deduplicated
    
    def _calculate_frequency(self, timestamps):
        """è®¡ç®—é”™è¯¯é¢‘ç‡ï¼ˆæ¬¡/åˆ†é’Ÿï¼‰"""
        if len(timestamps) < 2:
            return 0
        
        try:
            first = datetime.fromisoformat(timestamps[0].replace('Z', '+00:00'))
            last = datetime.fromisoformat(timestamps[-1].replace('Z', '+00:00'))
            duration_minutes = (last - first).total_seconds() / 60
            
            if duration_minutes == 0:
                return len(timestamps)
            
            return round(len(timestamps) / duration_minutes, 2)
        except:
            return 0
    
    # ==================== å¢å¼ºåŠŸèƒ½ï¼šé”™è¯¯ä¸¥é‡æ€§è¯„åˆ† ====================
    
    def calculate_severity_score(self, error):
        """è®¡ç®—é”™è¯¯ä¸¥é‡æ€§å¾—åˆ†ï¼ˆ0-100åˆ†ï¼‰"""
        score = 0
        details = {}
        
        # 1. é”™è¯¯ç±»å‹æƒé‡ (0-40åˆ†)
        category_scores = {
            'crash': 40,
            'anr': 30,
            'exception': 15
        }
        type_score = category_scores.get(error['category'], 10)
        score += type_score
        details['type_score'] = type_score
        
        # 2. å½±å“èŒƒå›´ (0-20åˆ†)
        impact_score = self._calculate_impact_score(error)
        score += impact_score
        details['impact_score'] = impact_score
        
        # 3. å¤ç°é¢‘ç‡ (0-20åˆ†)
        frequency_score = self._calculate_frequency_score(error)
        score += frequency_score
        details['frequency_score'] = frequency_score
        
        # 4. ç”¨æˆ·å½±å“ç¨‹åº¦ (0-20åˆ†)
        user_impact_score = self._calculate_user_impact_score(error)
        score += user_impact_score
        details['user_impact_score'] = user_impact_score
        
        # ç¡®å®šä¼˜å…ˆçº§
        priority = self._get_priority_level(score)
        
        return {
            'total_score': min(score, 100),
            'priority': priority,
            'details': details
        }
    
    def _calculate_impact_score(self, error):
        """è®¡ç®—å½±å“èŒƒå›´å¾—åˆ†"""
        score = 0
        process_name = error.get('processName', '').lower()
        context = ' '.join(error.get('context', [])).lower()
        
        # ä¸»è¿›ç¨‹å´©æºƒ
        if ':' not in process_name:
            score += 10
        
        # å…³é”®æ¨¡å—è¯†åˆ«
        critical_modules = [
            'activity', 'mainactivity', 'launcher',
            'payment', 'login', 'auth',
            'application', 'service'
        ]
        if any(module in process_name or module in context for module in critical_modules):
            score += 10
        
        return min(score, 20)
    
    def _calculate_frequency_score(self, error):
        """è®¡ç®—å¤ç°é¢‘ç‡å¾—åˆ†"""
        if 'deduplication' not in error:
            return 0
        
        occurrences = error['deduplication']['occurrences']
        
        if occurrences >= 10:
            return 20
        elif occurrences >= 5:
            return 15
        elif occurrences >= 3:
            return 10
        else:
            return 5
    
    def _calculate_user_impact_score(self, error):
        """è®¡ç®—ç”¨æˆ·å½±å“ç¨‹åº¦å¾—åˆ†"""
        context = ' '.join(error.get('context', [])).lower()
        
        # é˜»å¡å‹é”™è¯¯
        blocking_patterns = [
            'fatal', 'unable to start', 'cannot create',
            'force close', 'application not responding'
        ]
        if any(pattern in context for pattern in blocking_patterns):
            return 20
        
        # é™çº§å‹é”™è¯¯
        degraded_patterns = [
            'slow', 'timeout', 'retry',
            'null', 'not found', 'invalid'
        ]
        if any(pattern in context for pattern in degraded_patterns):
            return 10
        
        return 5
    
    def _get_priority_level(self, score):
        """æ ¹æ®å¾—åˆ†ç¡®å®šä¼˜å…ˆçº§"""
        if score >= 80:
            return 'CRITICAL'
        elif score >= 60:
            return 'HIGH'
        elif score >= 40:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def prioritize_errors(self, errors):
        """å¯¹æ‰€æœ‰é”™è¯¯è¿›è¡Œè¯„åˆ†å’Œæ’åº"""
        for error in errors:
            severity_info = self.calculate_severity_score(error)
            error['severity'] = severity_info
        
        # æŒ‰ä¸¥é‡æ€§å¾—åˆ†é™åºæ’åº
        errors.sort(key=lambda x: x['severity']['total_score'], reverse=True)
        
        return errors
    
    # ==================== å¢å¼ºåŠŸèƒ½ï¼šæ™ºèƒ½æ ¹å› å®šä½ ====================
    
    def analyze_root_cause(self, error):
        """æ™ºèƒ½æ ¹å› åˆ†æ"""
        context = ' '.join(error.get('context', []))
        
        # 1. è¯†åˆ«ä»£ç å½’å±
        code_attribution = self._identify_code_attribution(context)
        
        # 2. å®šä½æœ€å¯èƒ½çš„å‡ºé”™ç‚¹
        error_location = self._locate_error_point(context, code_attribution)
        
        # 3. è¯†åˆ«é”™è¯¯æ¨¡å¼
        error_pattern = self._identify_error_pattern(context)
        
        # 4. ç”Ÿæˆä¿®å¤å»ºè®®
        fix_suggestions = self._generate_fix_suggestions(error_pattern, error_location)
        
        return {
            'code_attribution': code_attribution,
            'error_location': error_location,
            'error_pattern': error_pattern,
            'fix_suggestions': fix_suggestions,
            'confidence': self._calculate_confidence(error_location, error_pattern)
        }
    
    def _identify_code_attribution(self, context):
        """è¯†åˆ«ä»£ç å½’å±"""
        stack_pattern = r'at ([\w\.$]+)\.(\w+)\(([\w\.]+):(\d+)\)'
        matches = re.findall(stack_pattern, context)
        
        attributions = []
        for class_path, method, file, line in matches:
            attribution = {
                'class': class_path,
                'method': method,
                'file': file,
                'line': int(line),
                'type': self._classify_code_type(class_path)
            }
            attributions.append(attribution)
        
        return attributions
    
    def _classify_code_type(self, class_path):
        """åˆ†ç±»ä»£ç ç±»å‹"""
        if class_path.startswith('android.') or class_path.startswith('java.'):
            return 'SYSTEM'
        elif any(lib in class_path for lib in ['okhttp', 'retrofit', 'glide', 'gson', 'kotlinx']):
            return 'THIRD_PARTY'
        else:
            return 'APPLICATION'
    
    def _locate_error_point(self, context, attributions):
        """å®šä½æœ€å¯èƒ½çš„å‡ºé”™ç‚¹"""
        # ä¼˜å…ˆæŸ¥æ‰¾åº”ç”¨ä»£ç 
        app_code = [attr for attr in attributions if attr['type'] == 'APPLICATION']
        
        if app_code:
            location = app_code[0]
        elif attributions:
            location = attributions[0]
        else:
            return None
        
        # æå–ä»£ç ç‰‡æ®µ
        location['code_snippet'] = self._extract_code_snippet(context, location)
        
        return location
    
    def _extract_code_snippet(self, context, location):
        """æå–ä»£ç ç‰‡æ®µæç¤º"""
        snippets = []
        
        # ä»Long Msgä¸­æå–
        long_msg_pattern = r'Long Msg: (.+?)(?://|$)'
        long_msgs = re.findall(long_msg_pattern, context)
        if long_msgs:
            snippets.extend(long_msgs)
        
        # ä»é”™è¯¯æè¿°ä¸­æå–
        desc_pattern = r'property (\w+)|variable (\w+)|method (\w+)'
        descs = re.findall(desc_pattern, context)
        snippets.extend([d for group in descs for d in group if d])
        
        return ' '.join(snippets[:3]) if snippets else None
    
    def _identify_error_pattern(self, context):
        """è¯†åˆ«é”™è¯¯æ¨¡å¼"""
        patterns = {
            'UNINITIALIZED_LATEINIT': {
                'keywords': ['UninitializedPropertyAccessException', 'lateinit property'],
                'name': 'æœªåˆå§‹åŒ–çš„lateinitå±æ€§',
                'description': 'Kotlinçš„lateinitå±æ€§åœ¨åˆå§‹åŒ–å‰è¢«è®¿é—®'
            },
            'NULL_POINTER': {
                'keywords': ['NullPointerException', 'null object reference'],
                'name': 'ç©ºæŒ‡é’ˆå¼‚å¸¸',
                'description': 'å°è¯•è®¿é—®nullå¯¹è±¡çš„æ–¹æ³•æˆ–å±æ€§'
            },
            'OUT_OF_MEMORY': {
                'keywords': ['OutOfMemoryError', 'Failed to allocate'],
                'name': 'å†…å­˜æº¢å‡º',
                'description': 'åº”ç”¨å†…å­˜ä¸è¶³ï¼Œæ— æ³•åˆ†é…æ–°å¯¹è±¡'
            },
            'RESOURCE_NOT_FOUND': {
                'keywords': ['Resources$NotFoundException', 'Resource ID'],
                'name': 'èµ„æºæœªæ‰¾åˆ°',
                'description': 'å°è¯•è®¿é—®ä¸å­˜åœ¨çš„èµ„æºæ–‡ä»¶'
            },
            'CONCURRENT_MODIFICATION': {
                'keywords': ['ConcurrentModificationException'],
                'name': 'å¹¶å‘ä¿®æ”¹å¼‚å¸¸',
                'description': 'åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ä¿®æ”¹äº†é›†åˆ'
            },
            'LIFECYCLE_ERROR': {
                'keywords': ['IllegalStateException', 'Can not perform this action after onSaveInstanceState'],
                'name': 'ç”Ÿå‘½å‘¨æœŸé”™è¯¯',
                'description': 'Activity/Fragmentç”Ÿå‘½å‘¨æœŸä½¿ç”¨ä¸å½“'
            }
        }
        
        context_lower = context.lower()
        for pattern_id, pattern_info in patterns.items():
            if any(keyword.lower() in context_lower for keyword in pattern_info['keywords']):
                return {
                    'id': pattern_id,
                    **pattern_info
                }
        
        return {
            'id': 'UNKNOWN',
            'name': 'æœªçŸ¥é”™è¯¯æ¨¡å¼',
            'description': 'éœ€è¦äººå·¥åˆ†æ'
        }
    
    def _generate_fix_suggestions(self, error_pattern, error_location):
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        suggestions_map = {
            'UNINITIALIZED_LATEINIT': [
                'åœ¨è®¿é—®å‰ä½¿ç”¨ ::property.isInitialized æ£€æŸ¥',
                'åœ¨æ„é€ å‡½æ•°æˆ–initå—ä¸­åˆå§‹åŒ–å±æ€§',
                'è€ƒè™‘æ”¹ç”¨å¯ç©ºç±»å‹ä»£æ›¿lateinit'
            ],
            'NULL_POINTER': [
                'ä½¿ç”¨å®‰å…¨è°ƒç”¨æ“ä½œç¬¦ ?.',
                'åœ¨è®¿é—®å‰è¿›è¡Œnullæ£€æŸ¥',
                'ä½¿ç”¨Elvisæ“ä½œç¬¦æä¾›é»˜è®¤å€¼'
            ],
            'OUT_OF_MEMORY': [
                'æ£€æŸ¥æ˜¯å¦å­˜åœ¨å†…å­˜æ³„æ¼',
                'ä¼˜åŒ–å›¾ç‰‡åŠ è½½ï¼Œä½¿ç”¨inSampleSizeå‹ç¼©',
                'åŠæ—¶é‡Šæ”¾ä¸å†ä½¿ç”¨çš„èµ„æº'
            ],
            'RESOURCE_NOT_FOUND': [
                'æ£€æŸ¥èµ„æºIDæ˜¯å¦æ­£ç¡®',
                'ç¡®è®¤èµ„æºåœ¨æ‰€æœ‰é…ç½®ä¸­éƒ½å­˜åœ¨'
            ],
            'LIFECYCLE_ERROR': [
                'ä½¿ç”¨commitAllowingStateLoss()ä»£æ›¿commit()',
                'åœ¨åˆé€‚çš„ç”Ÿå‘½å‘¨æœŸæ–¹æ³•ä¸­æ‰§è¡ŒFragmentäº‹åŠ¡'
            ]
        }
        
        pattern_id = error_pattern.get('id', 'UNKNOWN')
        suggestions = suggestions_map.get(pattern_id, ['æŸ¥çœ‹å®Œæ•´å †æ ˆä¿¡æ¯ï¼Œå®šä½å…·ä½“é—®é¢˜ä»£ç '])
        
        return suggestions[:3]  # æœ€å¤šè¿”å›3æ¡å»ºè®®
    
    def _calculate_confidence(self, error_location, error_pattern):
        """è®¡ç®—æ ¹å› å®šä½çš„ç½®ä¿¡åº¦"""
        confidence = 0
        
        if error_location:
            if error_location['type'] == 'APPLICATION':
                confidence += 50
            elif error_location['type'] == 'THIRD_PARTY':
                confidence += 30
            else:
                confidence += 10
        
        if error_pattern['id'] != 'UNKNOWN':
            confidence += 40
        
        if error_location and error_location.get('code_snippet'):
            confidence += 10
        
        return min(confidence, 100)
    
    # ==================== å¢å¼ºåŠŸèƒ½ï¼šé”™è¯¯ä¸Šä¸‹æ–‡å¢å¼º ====================
    
    def extract_environment_context(self, log_text):
        """æå–ç¯å¢ƒä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context = {
            'device': self._extract_device_info(log_text),
            'application': self._extract_app_info(log_text),
            'memory': self._extract_memory_info(log_text),
            'test_config': self._extract_test_config(log_text)
        }
        return context
    
    def _extract_device_info(self, log_text):
        """æå–è®¾å¤‡ä¿¡æ¯"""
        device_info = {}
        
        # æå–Build Label
        build_pattern = r'Build Label: (.+?)(?:\n|//|$)'
        build_match = re.search(build_pattern, log_text)
        if build_match:
            device_info['build_label'] = build_match.group(1).strip()
        
        # æå–Build Time
        time_pattern = r'Build Time: (\d+)'
        time_match = re.search(time_pattern, log_text)
        if time_match:
            timestamp = int(time_match.group(1)) / 1000
            device_info['build_time'] = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')
        
        # æå–Changelist
        change_pattern = r'Build Changelist: (\d+)'
        change_match = re.search(change_pattern, log_text)
        if change_match:
            device_info['changelist'] = change_match.group(1)
        
        return device_info
    
    def _extract_app_info(self, log_text):
        """æå–åº”ç”¨ä¿¡æ¯"""
        app_info = {}
        
        # ä»å´©æºƒæ—¥å¿—ä¸­æå–åŒ…å
        package_pattern = r'Process: ([\w\.]+)|CRASH: ([\w\.]+)'
        package_matches = re.findall(package_pattern, log_text)
        packages = set()
        for match in package_matches:
            pkg = match[0] or match[1]
            if pkg:
                packages.add(pkg)
        
        if packages:
            app_info['packages'] = list(packages)
        
        return app_info
    
    def _extract_memory_info(self, log_text):
        """æå–å†…å­˜ä¿¡æ¯"""
        memory_info = {}
        
        # æŸ¥æ‰¾OOMç›¸å…³ä¿¡æ¯
        if 'OutOfMemoryError' in log_text:
            memory_info['oom_detected'] = True
            
            # æå–å†…å­˜åˆ†é…å¤±è´¥ä¿¡æ¯
            alloc_pattern = r'Failed to allocate (\d+) bytes'
            alloc_match = re.search(alloc_pattern, log_text)
            if alloc_match:
                bytes_failed = int(alloc_match.group(1))
                memory_info['failed_allocation_bytes'] = bytes_failed
                memory_info['failed_allocation_mb'] = round(bytes_failed / 1024 / 1024, 2)
        
        return memory_info
    
    def _extract_test_config(self, log_text):
        """æå–æµ‹è¯•é…ç½®ä¿¡æ¯"""
        config = {}
        
        # æå–äº‹ä»¶æ•°
        events_pattern = r'Events injected: (\d+)'
        events_match = re.search(events_pattern, log_text)
        if events_match:
            config['events_injected'] = int(events_match.group(1))
        
        # æ£€æµ‹æµ‹è¯•æ˜¯å¦å®Œæˆ
        if 'Monkey finished' in log_text:
            config['status'] = 'COMPLETED'
        elif 'Monkey aborted' in log_text:
            config['status'] = 'ABORTED'
        else:
            config['status'] = 'UNKNOWN'
        
        return config
    
    # ==================== å¢å¼ºåŠŸèƒ½ï¼šæ™ºèƒ½æ€»ç»“ç”Ÿæˆ ====================
    
    def generate_executive_summary(self, errors, environment_context=None):
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        summary = []
        
        # æ ‡é¢˜
        summary.append("\n" + "=" * 80)
        summary.append(f"{EMOJI['clipboard']} Monkeyæµ‹è¯•æ‰§è¡Œæ‘˜è¦")
        summary.append("=" * 80)
        summary.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        summary.append(f"åˆ†æé”™è¯¯æ•°: {len(errors)}ä¸ª")
        summary.append("")
        
        # ç¯å¢ƒä¿¡æ¯
        if environment_context:
            summary.append(f"{EMOJI['phone']} æµ‹è¯•ç¯å¢ƒ")
            if environment_context.get('device'):
                device = environment_context['device']
                if device.get('build_label'):
                    summary.append(f"   è®¾å¤‡: {device['build_label']}")
                if device.get('build_time'):
                    summary.append(f"   æ„å»ºæ—¶é—´: {device['build_time']}")
            
            if environment_context.get('test_config'):
                config = environment_context['test_config']
                if config.get('events_injected'):
                    summary.append(f"   æ³¨å…¥äº‹ä»¶: {config['events_injected']}ä¸ª")
                if config.get('status'):
                    summary.append(f"   æµ‹è¯•çŠ¶æ€: {config['status']}")
            summary.append("")
        
        # ä¸¥é‡æ€§åˆ†æ
        priority_counts = self._count_by_priority(errors)
        summary.append(f"{EMOJI['target']} ä¸¥é‡æ€§åˆ†æ")
        
        critical_count = priority_counts.get('CRITICAL', 0)
        high_count = priority_counts.get('HIGH', 0)
        medium_count = priority_counts.get('MEDIUM', 0)
        low_count = priority_counts.get('LOW', 0)
        
        if critical_count > 0:
            summary.append(f"   {EMOJI['red_circle']} è‡´å‘½é”™è¯¯: {critical_count}ä¸ª (éœ€ç«‹å³ä¿®å¤)")
            # åˆ—å‡ºè‡´å‘½é”™è¯¯
            critical_errors = [e for e in errors if e.get('severity', {}).get('priority') == 'CRITICAL']
            for i, error in enumerate(critical_errors[:3], 1):
                process = error.get('processName', 'Unknown')
                pattern = error.get('rootCause', {}).get('error_pattern', {}).get('name', 'Unknown')
                summary.append(f"      {i}. [{error['category'].upper()}] {process}")
                summary.append(f"         é”™è¯¯: {pattern}")
                if 'deduplication' in error:
                    occurrences = error['deduplication']['occurrences']
                    summary.append(f"         å¤ç°: {occurrences}æ¬¡")
        
        if high_count > 0:
            summary.append(f"   {EMOJI['yellow_circle']} ä¸¥é‡é—®é¢˜: {high_count}ä¸ª (å»ºè®®æœ¬å‘¨ä¿®å¤)")
        
        summary.append(f"   {EMOJI['blue_circle']} ä¸­ç­‰é—®é¢˜: {medium_count}ä¸ª")
        summary.append(f"   {EMOJI['green_circle']} è¾ƒä½é—®é¢˜: {low_count}ä¸ª")
        summary.append("")
        
        # ç¨³å®šæ€§è¯„åˆ†
        stability_score = self._calculate_stability_score(errors)
        summary.append(f"{EMOJI['check']} ç¨³å®šæ€§è¯„åˆ†: {stability_score}/100")
        
        if stability_score >= 90:
            level, emoji = "ä¼˜ç§€", EMOJI['star']
        elif stability_score >= 75:
            level, emoji = "è‰¯å¥½", EMOJI['thumbs_up']
        elif stability_score >= 60:
            level, emoji = "ä¸€èˆ¬", EMOJI['warning']
        else:
            level, emoji = "è¾ƒå·®", EMOJI['cross']
        
        summary.append(f"   {emoji} è¯„çº§: {level}")
        summary.append("")
        
        # å…³é”®å»ºè®®
        summary.append(f"{EMOJI['bulb']} å…³é”®å»ºè®®")
        recommendations = self._generate_key_recommendations(errors, priority_counts)
        for i, rec in enumerate(recommendations, 1):
            summary.append(f"   {i}. {rec}")
        summary.append("")
        
        summary.append("=" * 80)
        
        return '\n'.join(summary)
    
    def _count_by_priority(self, errors):
        """æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡"""
        counts = defaultdict(int)
        for error in errors:
            priority = error.get('severity', {}).get('priority', 'UNKNOWN')
            counts[priority] += 1
        return dict(counts)
    
    def _calculate_stability_score(self, errors):
        """è®¡ç®—ç¨³å®šæ€§è¯„åˆ†ï¼ˆ0-100ï¼‰"""
        score = 100
        
        # æ ¹æ®é”™è¯¯æ•°é‡æ‰£åˆ†
        total_errors = len(errors)
        if total_errors > 0:
            score -= min(total_errors * 2, 40)
        
        # æ ¹æ®ä¸¥é‡æ€§æ‰£åˆ†
        for error in errors:
            priority = error.get('severity', {}).get('priority', 'LOW')
            deduction = {
                'CRITICAL': 10,
                'HIGH': 5,
                'MEDIUM': 2,
                'LOW': 1
            }
            score -= deduction.get(priority, 0)
        
        # æ ¹æ®å¤ç°é¢‘ç‡æ‰£åˆ†
        for error in errors:
            if 'deduplication' in error:
                occurrences = error['deduplication']['occurrences']
                if occurrences > 10:
                    score -= 5
                elif occurrences > 5:
                    score -= 3
        
        return max(score, 0)
    
    def _generate_key_recommendations(self, errors, priority_counts):
        """ç”Ÿæˆå…³é”®ä¿®å¤å»ºè®®"""
        recommendations = []
        
        critical_count = priority_counts.get('CRITICAL', 0)
        high_count = priority_counts.get('HIGH', 0)
        
        if critical_count > 0:
            recommendations.append(f"ç«‹å³ä¿®å¤{critical_count}ä¸ªè‡´å‘½é”™è¯¯ï¼Œè¿™äº›é”™è¯¯ä¸¥é‡å½±å“åº”ç”¨å¯ç”¨æ€§")
        
        if high_count > 0:
            recommendations.append(f"æœ¬å‘¨å†…ä¿®å¤{high_count}ä¸ªä¸¥é‡é—®é¢˜ï¼Œé¿å…å½±å“ç”¨æˆ·ä½“éªŒ")
        
        # åˆ†æé«˜é¢‘é”™è¯¯
        high_freq_errors = [
            e for e in errors 
            if e.get('deduplication', {}).get('occurrences', 1) > 5
        ]
        if high_freq_errors:
            recommendations.append(f"ä¼˜å…ˆå¤„ç†{len(high_freq_errors)}ä¸ªé«˜é¢‘é”™è¯¯ï¼Œè¿™äº›é—®é¢˜å®¹æ˜“è¢«ç”¨æˆ·è§¦å‘")
        
        # å†…å­˜é—®é¢˜
        oom_errors = [e for e in errors if 'OutOfMemoryError' in str(e.get('context', []))]
        if oom_errors:
            recommendations.append("ä½¿ç”¨LeakCanaryæˆ–Profilerå·¥å…·æ’æŸ¥å†…å­˜æ³„æ¼é—®é¢˜")
        
        # ANRé—®é¢˜
        anr_errors = [e for e in errors if e['category'] == 'anr']
        if anr_errors:
            recommendations.append("ä¼˜åŒ–ä¸»çº¿ç¨‹æ“ä½œï¼Œå°†è€—æ—¶ä»»åŠ¡ç§»è‡³åå°çº¿ç¨‹")
        
        # å¦‚æœæ²¡æœ‰å…¶ä»–å»ºè®®
        if not recommendations:
            recommendations.append("ç»§ç»­ä¿æŒæµ‹è¯•è¦†ç›–ï¼Œç›‘æ§åº”ç”¨ç¨³å®šæ€§")
        
        return recommendations[:5]

    def analyze_monkey_log(self, output_format='list', enable_correlation=False):
        """æ‰§è¡Œç»¼åˆåˆ†æ
        
        Args:
            output_format: è¾“å‡ºæ ¼å¼ï¼Œ'list'ä¸ºåˆ—è¡¨å¼ï¼Œ'json'ä¸ºJSONæ ¼å¼
            enable_correlation: æ˜¯å¦å¯ç”¨å…³è”åˆ†æï¼Œè¿‡æ»¤è¡ç”Ÿé”™è¯¯ï¼ˆä»…JSONæ ¼å¼æœ‰æ•ˆï¼‰
        """
        if not self.monkey_log:
            safe_print(f"{EMOJI['cross']} æ²¡æœ‰å¯åˆ†æçš„Monkeyæ—¥å¿—")
            return
        
        print("\n" + "="*80)
        print("Monkeyæ—¥å¿—æ ¹å› åˆ†æ")
        print("="*80)
        
        log_text = "".join(self.monkey_log)
        
        # æ‰§è¡Œå„é¡¹åˆ†æ
        self._analyze_crashes(log_text)
        self._analyze_anrs(log_text)
        self._analyze_exceptions(log_text)
        self._analyze_test_summary(log_text)
        
        # æ ¹æ®æ ¼å¼ç”Ÿæˆå¯¹åº”æŠ¥å‘Š
        if output_format == 'json':
            self.print_json_report(enable_correlation)
        else:
            self.generate_list_style_report()

    def _analyze_crashes(self, log_text):
        """åˆ†æå´©æºƒä¿¡æ¯"""
        crash_pattern = r'// CRASH: (.+?) \(pid (\d+)\)'
        crash_matches = re.findall(crash_pattern, log_text)
        
        for process_name, pid in crash_matches:
            error_section = self._extract_error_section(log_text, f"CRASH: {process_name}")
            stack_trace = self._extract_stack_trace(log_text, process_name)
            context_lines = self._extract_context_lines(log_text, f"CRASH: {process_name}")
            
            # è¿‡æ»¤æ‰Monkeyè‡ªèº«çš„é”™è¯¯
            if self._is_monkey_internal_error(process_name, error_section + stack_trace):
                continue
            
            crash_info = {
                'process': process_name,
                'pid': pid,
                'type': 'åº”ç”¨å´©æºƒ',
                'severity': 'CRITICAL',
                'timestamp': self._extract_timestamp(error_section if error_section else "\n".join(context_lines)),
                'error_details': error_section[:500] if error_section else "æ— è¯¦ç»†é”™è¯¯ä¿¡æ¯",
                'stack_trace': stack_trace[:1000] if stack_trace else "æ— å †æ ˆä¿¡æ¯",
                'exception_type': self._extract_exception_type(stack_trace),
                'root_cause': self._analyze_root_cause(stack_trace, error_section),
                'context': context_lines  # æ–°å¢ï¼šå®Œæ•´ä¸Šä¸‹æ–‡è¡Œ
            }
            
            self.analysis_results['crashes'].append(crash_info)

    def _analyze_anrs(self, log_text):
        """åˆ†æANRä¿¡æ¯"""
        anr_pattern = r'// NOT RESPONDING: (.+?) \(pid (\d+)\)'
        anr_matches = re.findall(anr_pattern, log_text)
        
        for process_name, pid in anr_matches:
            context_lines = self._extract_context_lines(log_text, f"NOT RESPONDING: {process_name}")
            
            # è¿‡æ»¤æ‰Monkeyè‡ªèº«çš„é”™è¯¯
            context_str = "\n".join(context_lines) if context_lines else ""
            if self._is_monkey_internal_error(process_name, context_str):
                continue
            
            anr_info = {
                'process': process_name,
                'pid': pid,
                'type': 'åº”ç”¨æ— å“åº”',
                'severity': 'HIGH',
                'timestamp': self._extract_timestamp(context_str),
                'root_cause': self._analyze_anr_cause(log_text, process_name),
                'suggestions': [
                    "æ£€æŸ¥ä¸»çº¿ç¨‹ä¸­çš„è€—æ—¶æ“ä½œ",
                    "ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œæ–‡ä»¶IO",
                    "å‡å°‘ç½‘ç»œè¯·æ±‚é˜»å¡",
                    "ä½¿ç”¨å¼‚æ­¥ä»»åŠ¡å¤„ç†åå°å·¥ä½œ"
                ],
                'context': context_lines  # æ–°å¢ï¼šå®Œæ•´ä¸Šä¸‹æ–‡è¡Œ
            }
            
            self.analysis_results['anrs'].append(anr_info)

    def _analyze_exceptions(self, log_text):
        """åˆ†æå¼‚å¸¸ä¿¡æ¯"""
        exception_keywords = ['Exception', 'Error', 'Fatal', 'FAILED']
        
        for i, line in enumerate(self.monkey_log):
            if any(keyword in line for keyword in exception_keywords):
                # è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯
                context_start = max(0, i-2)
                context_end = min(len(self.monkey_log), i+5)
                context = "".join(self.monkey_log[context_start:context_end])
                
                # è¿‡æ»¤æ‰Monkeyè‡ªèº«çš„é”™è¯¯
                process_name = self._extract_process_from_context(context)
                if self._is_monkey_internal_error(process_name, context + line):
                    continue
                
                exception_info = {
                    'process': process_name,
                    'type': 'è¿è¡Œæ—¶å¼‚å¸¸',
                    'severity': 'MEDIUM',
                    'timestamp': self._extract_timestamp(context + line),
                    'details': line.strip(),
                    'context': context[:300],
                    'root_cause': self._classify_exception(line)
                }
                
                self.analysis_results['exceptions'].append(exception_info)

    def _analyze_test_summary(self, log_text):
        """åˆ†ææµ‹è¯•æ‘˜è¦"""
        summary = {}
        
        if 'Monkey finished' in log_text:
            summary['status'] = 'å®Œæˆ'
            finished_match = re.search(r'Events injected: (\d+)', log_text)
            if finished_match:
                summary['events_injected'] = finished_match.group(1)
        else:
            summary['status'] = 'æœªå®Œæˆæˆ–ä¸­æ­¢'
        
        if 'Monkey aborted due to error' in log_text:
            summary['abort_reason'] = 'å› é”™è¯¯ä¸­æ­¢'
        
        summary['total_crashes'] = len(self.analysis_results['crashes'])
        summary['total_anrs'] = len(self.analysis_results['anrs'])
        summary['total_exceptions'] = len(self.analysis_results['exceptions'])
        
        self.analysis_results['test_summary'] = summary

    def _extract_error_section(self, log_text, crash_keyword):
        """æå–é”™è¯¯è¯¦æƒ…éƒ¨åˆ†"""
        lines = log_text.split('\n')
        error_section = []
        capture = False
        
        for line in lines:
            if crash_keyword in line:
                capture = True
            if capture:
                error_section.append(line)
                if not line.strip().startswith('//') and line.strip():
                    break
        
        return "\n".join(error_section)

    def _extract_stack_trace(self, log_text, process_name):
        """æå–å †æ ˆè½¨è¿¹"""
        lines = log_text.split('\n')
        stack_trace = []
        capture = False
        
        for line in lines:
            if process_name in line and ('Exception' in line or 'Error' in line):
                capture = True
            if capture:
                stack_trace.append(line)
                if not line.strip() and len(stack_trace) > 5:
                    break
        
        return "\n".join(stack_trace)

    def _extract_process_from_context(self, context):
        """ä»ä¸Šä¸‹æ–‡ä¸­æå–è¿›ç¨‹ä¿¡æ¯"""
        process_match = re.search(r'Process: ([^,]+), PID: (\d+)', context)
        if process_match:
            return f"{process_match.group(1)} (PID: {process_match.group(2)})"
        
        package_match = re.search(r'([a-z][a-z0-9_]*(\.[a-z][a-z0-9_]*)+)', context)
        if package_match:
            return package_match.group(1)
        
        return "æœªçŸ¥è¿›ç¨‹"

    def _extract_exception_type(self, stack_trace):
        """æå–å¼‚å¸¸ç±»å‹"""
        exception_pattern = r'([a-zA-Z0-9_.]+(?:Exception|Error))'
        matches = re.findall(exception_pattern, stack_trace)
        return matches[0] if matches else "Unknown"

    def _extract_timestamp(self, text):
        """ä»æ–‡æœ¬ä¸­æå–æ—¶é—´æˆ³
        
        æ”¯æŒæ ¼å¼ï¼š
        1. Build Time: 1762325307000 (Monkey æ—¥å¿—ä¸­çš„ Unix æ—¶é—´æˆ³ï¼Œæ¯«ç§’)
        2. YYYY-MM-DD HH:MM:SS (æ ‡å‡†æ ¼å¼)
        3. æ‰¾ä¸åˆ°æ—¶è¿”å›å½“å‰æ—¶é—´
        """
        # 1. ä¼˜å…ˆæå– Build Time (Monkey æ—¥å¿—æ ¼å¼: Unix æ—¶é—´æˆ³æ¯«ç§’)
        build_time_match = re.search(r'Build Time:\s*(\d{13})', text)
        if build_time_match:
            try:
                unix_ms = int(build_time_match.group(1))
                dt = datetime.fromtimestamp(unix_ms / 1000.0)
                return dt.strftime("%Y-%m-%d %H:%M:%S")
            except (ValueError, OSError):
                pass  # æ—¶é—´æˆ³æ— æ•ˆï¼Œç»§ç»­å°è¯•å…¶ä»–æ ¼å¼
        
        # 2. å°è¯•æ ‡å‡†æ ¼å¼ (å…¼å®¹å…¶ä»–æ—¥å¿—)
        timestamp_match = re.search(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', text)
        if timestamp_match:
            return timestamp_match.group(1)
        
        # 3. æ‰¾ä¸åˆ°æ—¶è¿”å›å½“å‰æ—¶é—´
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def _extract_context_lines(self, log_text, keyword):
        """æå–é”™è¯¯çš„å®Œæ•´ä¸Šä¸‹æ–‡è¡Œï¼ˆç”¨äºJSONè¾“å‡ºï¼‰"""
        lines = log_text.split('\n')
        context = []
        capture = False
        line_count = 0
        max_lines = 20  # æœ€å¤šæå–20è¡Œä¸Šä¸‹æ–‡
        
        for line in lines:
            if keyword in line:
                capture = True
            
            if capture:
                # æå–ä»¥//å¼€å¤´çš„æ³¨é‡Šè¡Œå’Œå †æ ˆä¿¡æ¯
                if line.strip().startswith('//') or line.strip().startswith('at '):
                    context.append(line.strip())
                    line_count += 1
                elif line.strip() and not line.strip().startswith('**'):
                    # åŒ…å«å¼‚å¸¸ä¿¡æ¯è¡Œ
                    if 'Exception' in line or 'Error' in line:
                        context.append(line.strip())
                        line_count += 1
                
                # è¾¾åˆ°æœ€å¤§è¡Œæ•°æˆ–é‡åˆ°ç©ºè¡Œåˆ™åœæ­¢
                if line_count >= max_lines or (not line.strip() and len(context) > 5):
                    break
        
        return context

    def _analyze_root_cause(self, stack_trace, error_details):
        """åˆ†æå´©æºƒæ ¹æœ¬åŸå› """
        causes = []
        
        # ç©ºæŒ‡é’ˆå¼‚å¸¸
        if 'NullPointerException' in stack_trace:
            causes.append({
                'type': 'ç©ºæŒ‡é’ˆå¼‚å¸¸',
                'description': 'å°è¯•è®¿é—®ç©ºå¯¹è±¡çš„æ–¹æ³•æˆ–å­—æ®µ',
                'solution': 'æ£€æŸ¥å¯¹è±¡åˆå§‹åŒ–ï¼Œæ·»åŠ éç©ºéªŒè¯',
                'confidence': 'é«˜'
            })
        
        # å†…å­˜æº¢å‡º
        if 'OutOfMemoryError' in stack_trace:
            causes.append({
                'type': 'å†…å­˜æº¢å‡º',
                'description': 'å †å†…å­˜æˆ–Nativeå†…å­˜ä¸è¶³',
                'solution': 'æ£€æŸ¥BitmapåŠ è½½ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨',
                'confidence': 'é«˜'
            })
        
        # æƒé™é—®é¢˜
        if 'Permission Denial' in stack_trace or 'SecurityException' in stack_trace:
            causes.append({
                'type': 'æƒé™æ‹’ç»',
                'description': 'ç¼ºå°‘å¿…è¦çš„æƒé™æˆ–ç­¾åä¸åŒ¹é…',
                'solution': 'æ£€æŸ¥æƒé™å£°æ˜å’Œè¿è¡Œæ—¶è¯·æ±‚',
                'confidence': 'ä¸­'
            })
        
        # ç½‘ç»œé—®é¢˜
        if 'NetworkOnMainThreadException' in stack_trace:
            causes.append({
                'type': 'ä¸»çº¿ç¨‹ç½‘ç»œè¯·æ±‚',
                'description': 'åœ¨ä¸»çº¿ç¨‹æ‰§è¡Œç½‘ç»œæ“ä½œ',
                'solution': 'å°†ç½‘ç»œè¯·æ±‚ç§»è‡³åå°çº¿ç¨‹',
                'confidence': 'é«˜'
            })
        
        # æ•°æ®åº“é—®é¢˜
        if 'SQLiteException' in stack_trace:
            causes.append({
                'type': 'æ•°æ®åº“å¼‚å¸¸',
                'description': 'æ•°æ®åº“æ“ä½œå¤±è´¥',
                'solution': 'æ£€æŸ¥æ•°æ®åº“ç‰ˆæœ¬å’Œè¡¨ç»“æ„',
                'confidence': 'ä¸­'
            })
        
        # èµ„æºé—®é¢˜
        if 'Resources$NotFoundException' in stack_trace:
            causes.append({
                'type': 'èµ„æºæœªæ‰¾åˆ°',
                'description': 'å¼•ç”¨çš„èµ„æºæ–‡ä»¶ä¸å­˜åœ¨',
                'solution': 'æ£€æŸ¥èµ„æºIDå’Œæ–‡ä»¶å­˜åœ¨æ€§',
                'confidence': 'ä¸­'
            })
        
        return causes if causes else [{
            'type': 'æœªçŸ¥åŸå› ',
            'description': 'éœ€è¦è¿›ä¸€æ­¥åˆ†æå †æ ˆä¿¡æ¯',
            'solution': 'æŸ¥çœ‹å®Œæ•´æ—¥å¿—å †æ ˆ',
            'confidence': 'ä½'
        }]

    def _analyze_anr_cause(self, log_text, process_name):
        """åˆ†æANRåŸå› """
        causes = []
        
        # æ£€æŸ¥ANRä¸Šä¸‹æ–‡
        anr_context = self._extract_anr_context(log_text, process_name)
        
        if 'Input dispatching timed out' in anr_context:
            causes.append({
                'type': 'è¾“å…¥äº‹ä»¶è¶…æ—¶',
                'description': 'ä¸»çº¿ç¨‹å¤„ç†è¾“å…¥äº‹ä»¶è¶…æ—¶',
                'solution': 'æ£€æŸ¥ä¸»çº¿ç¨‹è€—æ—¶æ“ä½œ',
                'confidence': 'é«˜'
            })
        
        if 'executing service' in anr_context:
            causes.append({
                'type': 'æœåŠ¡æ‰§è¡Œè¶…æ—¶',
                'description': 'Serviceæ‰§è¡Œæ—¶é—´è¿‡é•¿',
                'solution': 'ä¼˜åŒ–Serviceé€»è¾‘ï¼Œä½¿ç”¨IntentService',
                'confidence': 'ä¸­'
            })
        
        if 'Broadcast of Intent' in anr_context:
            causes.append({
                'type': 'å¹¿æ’­å¤„ç†è¶…æ—¶',
                'description': 'BroadcastReceiveræ‰§è¡Œè¶…æ—¶',
                'solution': 'å°†å¹¿æ’­å¤„ç†ç§»è‡³åå°çº¿ç¨‹',
                'confidence': 'ä¸­'
            })
        
        if 'CPU usage' in anr_context and '100%' in anr_context:
            causes.append({
                'type': 'ç³»ç»Ÿèµ„æºè€—å°½',
                'description': 'CPUä½¿ç”¨ç‡è¾¾åˆ°100%',
                'solution': 'æ£€æŸ¥æ€§èƒ½ç“¶é¢ˆï¼Œä¼˜åŒ–èµ„æºä½¿ç”¨',
                'confidence': 'é«˜'
            })
        
        return causes if causes else [{
            'type': 'æœªçŸ¥ANRåŸå› ',
            'description': 'éœ€è¦æŸ¥çœ‹ç³»ç»ŸANRæ—¥å¿—',
            'solution': 'æ£€æŸ¥/data/anr/traces.txtæ–‡ä»¶',
            'confidence': 'ä½'
        }]

    def _extract_anr_context(self, log_text, process_name):
        """æå–ANRä¸Šä¸‹æ–‡"""
        lines = log_text.split('\n')
        anr_context = []
        capture = False
        
        for line in lines:
            if 'NOT RESPONDING' in line and process_name in line:
                capture = True
            if capture:
                anr_context.append(line)
                if 'CPU usage' in line or 'Load:' in line:
                    break
        
        return "\n".join(anr_context)

    def _classify_exception(self, exception_line):
        """åˆ†ç±»å¼‚å¸¸ç±»å‹"""
        if 'NullPointerException' in exception_line:
            return 'ç©ºæŒ‡é’ˆå¼‚å¸¸'
        elif 'OutOfMemoryError' in exception_line:
            return 'å†…å­˜æº¢å‡º'
        elif 'NetworkOnMainThreadException' in exception_line:
            return 'ä¸»çº¿ç¨‹ç½‘ç»œè¯·æ±‚'
        elif 'SQLiteException' in exception_line:
            return 'æ•°æ®åº“å¼‚å¸¸'
        elif 'Resources$NotFoundException' in exception_line:
            return 'èµ„æºæœªæ‰¾åˆ°'
        elif 'SecurityException' in exception_line:
            return 'æƒé™å¼‚å¸¸'
        else:
            return 'å…¶ä»–å¼‚å¸¸'

    def generate_list_style_report(self):
        """ç”Ÿæˆåˆ—è¡¨å¼æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("MONKEYæµ‹è¯•åˆ†ææŠ¥å‘Š - åˆ—è¡¨å¼")
        print("="*80)
        
        # æµ‹è¯•æ¦‚è§ˆ
        self._print_test_overview()
        
        # å´©æºƒé—®é¢˜åˆ—è¡¨
        self._print_crash_list()
        
        # ANRé—®é¢˜åˆ—è¡¨
        self._print_anr_list()
        
        # å¼‚å¸¸é—®é¢˜åˆ—è¡¨
        self._print_exception_list()
        
        # ä¿®å¤å»ºè®®æ€»ç»“
        self._print_recommendations_summary()
    
    def generate_json_report(self, enable_correlation=False):
        """ç”ŸæˆJSONæ ¼å¼æŠ¥å‘Šï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            enable_correlation: æ˜¯å¦å¯ç”¨å…³è”åˆ†æï¼Œè¿‡æ»¤è¡ç”Ÿé”™è¯¯
        
        å¢å¼ºåŠŸèƒ½ï¼š
        1. æ™ºèƒ½é”™è¯¯å»é‡
        2. é”™è¯¯ä¸¥é‡æ€§è¯„åˆ†
        3. æ™ºèƒ½æ ¹å› å®šä½
        4. ç¯å¢ƒä¸Šä¸‹æ–‡æå–
        """
        json_errors = []
        
        # å¤„ç†å´©æºƒä¿¡æ¯
        for crash in self.analysis_results['crashes']:
            error_obj = {
                "category": "crash",
                "processName": crash['process'],
                "pid": crash.get('pid', ''),
                "timestamp": self._format_iso_timestamp(crash.get('timestamp', '')),
                "context": crash.get('context', [])
            }
            json_errors.append(error_obj)
        
        # å¤„ç†ANRä¿¡æ¯
        for anr in self.analysis_results['anrs']:
            error_obj = {
                "category": "anr",
                "processName": anr['process'],
                "pid": anr.get('pid', ''),
                "timestamp": self._format_iso_timestamp(anr.get('timestamp', '')),
                "context": anr.get('context', [])
            }
            json_errors.append(error_obj)
        
        # å¤„ç†å¼‚å¸¸ä¿¡æ¯
        for exception in self.analysis_results['exceptions']:
            error_obj = {
                "category": "exception",
                "processName": exception['process'],
                "timestamp": self._format_iso_timestamp(exception.get('timestamp', '')),
                "context": [exception.get('details', '')] + [exception.get('context', '')]
            }
            json_errors.append(error_obj)
        
        # === åº”ç”¨å¢å¼ºåŠŸèƒ½ ===
        
        # 1. æ™ºèƒ½é”™è¯¯å»é‡
        safe_print(f"   {EMOJI['process']} æ­£åœ¨è¿›è¡Œæ™ºèƒ½å»é‡...")
        original_count = len(json_errors)
        json_errors = self.deduplicate_errors(json_errors)
        safe_print(f"   {EMOJI['check']} å»é‡å®Œæˆ: {original_count}ä¸ªé”™è¯¯ -> {len(json_errors)}ä¸ªç‹¬ç‰¹é”™è¯¯")
        
        # 2. é”™è¯¯ä¸¥é‡æ€§è¯„åˆ†
        safe_print(f"   {EMOJI['chart']} æ­£åœ¨è®¡ç®—ä¸¥é‡æ€§è¯„åˆ†...")
        json_errors = self.prioritize_errors(json_errors)
        critical_count = sum(1 for e in json_errors if e.get('severity', {}).get('priority') == 'CRITICAL')
        safe_print(f"   {EMOJI['check']} è¯„åˆ†å®Œæˆ: å‘ç°{critical_count}ä¸ªè‡´å‘½é”™è¯¯")
        
        # 3. æ™ºèƒ½æ ¹å› å®šä½
        safe_print(f"   {EMOJI['search']} æ­£åœ¨è¿›è¡Œæ ¹å› å®šä½...")
        for error in json_errors:
            error['rootCause'] = self.analyze_root_cause(error)
        high_confidence = sum(1 for e in json_errors if e.get('rootCause', {}).get('confidence', 0) >= 80)
        safe_print(f"   {EMOJI['check']} æ ¹å› å®šä½å®Œæˆ: {high_confidence}ä¸ªé”™è¯¯å®šä½ç½®ä¿¡åº¦â‰¥80%")
        
        # 4. å¯ç”¨å…³è”åˆ†ææ—¶ï¼Œè¿‡æ»¤è¡ç”Ÿé”™è¯¯
        if enable_correlation:
            safe_print(f"   {EMOJI['search']} æ­£åœ¨è¿›è¡Œå…³è”åˆ†æ...")
            original_count = len(json_errors)
            json_errors = self._filter_derived_errors(json_errors)
            safe_print(f"   {EMOJI['check']} å…³è”åˆ†æå®Œæˆ: è¿‡æ»¤äº†{original_count - len(json_errors)}ä¸ªè¡ç”Ÿé”™è¯¯")
        
        return json_errors
    
    def _filter_derived_errors(self, errors):
        """å¤šå¼‚å¸¸é“¾æ ¹å› åˆ†æï¼šè¯†åˆ«å¹¶è¿‡æ»¤è¡ç”Ÿé”™è¯¯ï¼Œä»…ä¿ç•™æ ¹æœ¬åŸå› 
        
        åˆ†æç­–ç•¥ï¼š
        1. æ—¶é—´é¡ºåºåˆ†æ - ç¬¬ä¸€ä¸ªå‘ç”Ÿçš„å¼‚å¸¸é€šå¸¸æ˜¯æ ¹æœ¬åŸå› 
        2. è°ƒç”¨é“¾åˆ†æ - åˆ†æå †æ ˆçš„è°ƒç”¨å…³ç³»ï¼Œå¯»æ‰¾æœ€æ·±å±‚çš„åŸå§‹é”™è¯¯ç‚¹
        3. å› æœå…³ç³»è¯†åˆ« - è¯†åˆ«å¼‚å¸¸ä¹‹é—´çš„ç›´æ¥å› æœå…³ç³»
        4. ä¸Šä¸‹æ–‡å…³è” - ç»“åˆæ—¥å¿—ä¸Šä¸‹æ–‡åˆ¤æ–­å¼‚å¸¸ç›¸å…³æ€§
        """
        if not errors:
            return errors
        
        # 1. æ—¶é—´é¡ºåºåˆ†æï¼šæŒ‰æ—¶é—´æ’åºï¼Œæœ€æ—©çš„é”™è¯¯ä¼˜å…ˆ
        errors.sort(key=lambda x: x.get('timestamp', ''))
        
        # æ„å»ºå¼‚å¸¸é“¾åˆ†ç»„
        error_chains = self._build_error_chains(errors)
        
        # 2. ä»æ¯ä¸ªå¼‚å¸¸é“¾ä¸­è¯†åˆ«æ ¹å› 
        root_causes = []
        for chain in error_chains:
            root_error = self._identify_root_cause(chain)
            if root_error:
                root_causes.append(root_error)
        
        return root_causes
    
    def _build_error_chains(self, errors):
        """æ„å»ºå¼‚å¸¸é“¾åˆ†ç»„ï¼šå°†ç›¸å…³çš„å¼‚å¸¸å½’ä¸ºä¸€ç»„
        
        åŸºäºï¼š
        - æ—¶é—´çª—å£ï¼ˆ5ç§’å†…ï¼‰
        - è¿›ç¨‹å…³è”
        - é”™è¯¯ç‰¹å¾ç›¸ä¼¼åº¦
        """
        if not errors:
            return []
        
        chains = []
        used_indices = set()
        
        for i, error in enumerate(errors):
            if i in used_indices:
                continue
            
            # å¼€å§‹æ–°çš„å¼‚å¸¸é“¾
            chain = [error]
            used_indices.add(i)
            
            # æŸ¥æ‰¾ä¸å½“å‰é”™è¯¯ç›¸å…³çš„åç»­é”™è¯¯
            for j in range(i + 1, len(errors)):
                if j in used_indices:
                    continue
                
                if self._is_related_error(error, errors[j], chain):
                    chain.append(errors[j])
                    used_indices.add(j)
            
            chains.append(chain)
        
        return chains
    
    def _is_related_error(self, error1, error2, chain):
        """åˆ¤æ–­ä¸¤ä¸ªé”™è¯¯æ˜¯å¦ç›¸å…³ï¼ˆå±äºåŒä¸€å¼‚å¸¸é“¾ï¼‰
        
        åˆ¤æ–­ç»´åº¦ï¼š
        1. æ—¶é—´çª—å£ï¼ˆ5ç§’å†…ï¼‰
        2. è¿›ç¨‹å…³è”
        3. é”™è¯¯ç‰¹å¾åŒ¹é…
        4. è°ƒç”¨é“¾å…³è”
        """
        # 1. æ—¶é—´çª—å£æ£€æŸ¥ï¼ˆ5ç§’å†…ï¼‰
        try:
            time1 = datetime.fromisoformat(error1['timestamp'].replace('Z', '+00:00'))
            time2 = datetime.fromisoformat(error2['timestamp'].replace('Z', '+00:00'))
            time_diff = abs((time2 - time1).total_seconds())
            
            if time_diff > 5:
                return False
        except:
            pass
        
        # 2. è¿›ç¨‹å…³è”æ£€æŸ¥
        process1 = error1.get('processName', '')
        process2 = error2.get('processName', '')
        
        # è¿›ç¨‹ä¸ç›¸å…³åˆ™ä¸å±äºåŒä¸€å¼‚å¸¸é“¾
        if not self._is_process_related(process1, process2):
            return False
        
        # 3. é”™è¯¯ç‰¹å¾åŒ¹é…ï¼ˆæ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸åŒçš„å¼‚å¸¸ç±»å‹æˆ–é”™è¯¯ä¿¡æ¯ï¼‰
        context1 = ' '.join(error1.get('context', []))
        context2 = ' '.join(error2.get('context', []))
        
        # æå–å¼‚å¸¸ç‰¹å¾
        features1 = self._extract_error_features(context1)
        features2 = self._extract_error_features(context2)
        
        # æ£€æŸ¥ç‰¹å¾é‡å åº¦
        if self._has_feature_overlap(features1, features2):
            return True
        
        # 4. è°ƒç”¨é“¾å…³è”æ£€æŸ¥
        if self._has_call_stack_relation(context1, context2):
            return True
        
        return False
    
    def _is_process_related(self, process1, process2):
        """åˆ¤æ–­ä¸¤ä¸ªè¿›ç¨‹æ˜¯å¦ç›¸å…³"""
        if not process1 or not process2:
            return False
        
        # å®Œå…¨ç›¸åŒ
        if process1 == process2:
            return True
        
        # ä¸€ä¸ªæ˜¯å¦ä¸€ä¸ªçš„å­æ¨¡å—
        if process1 in process2 or process2 in process1:
            return True
        
        # åŒä¸€ä¸ªåº”ç”¨çš„ä¸åŒç»„ä»¶
        parts1 = process1.split('.')
        parts2 = process2.split('.')
        if len(parts1) >= 3 and len(parts2) >= 3:
            # å‰ä¸‰æ®µç›¸åŒåˆ™è®¤ä¸ºæ˜¯åŒä¸€åº”ç”¨
            if parts1[:3] == parts2[:3]:
                return True
        
        return False
    
    def _extract_error_features(self, context):
        """æå–é”™è¯¯ç‰¹å¾ç”¨äºå…³è”åˆ†æ"""
        features = {
            'exception_types': [],
            'error_messages': [],
            'key_methods': [],
            'error_codes': []
        }
        
        # æå–å¼‚å¸¸ç±»å‹
        exception_pattern = r'(\w+Exception|\w+Error)'
        features['exception_types'] = re.findall(exception_pattern, context)
        
        # æå–é”™è¯¯æ¶ˆæ¯
        msg_patterns = [
            r'Short Msg: (.+?)(?://|$)',
            r'Long Msg: (.+?)(?://|$)',
            r'lateinit property (\w+)',
        ]
        for pattern in msg_patterns:
            matches = re.findall(pattern, context)
            features['error_messages'].extend(matches)
        
        # æå–å…³é”®æ–¹æ³•ï¼ˆè°ƒç”¨é“¾é¡¶éƒ¨ï¼‰
        method_pattern = r'at ([\w\.$]+\.[\w]+)\('
        methods = re.findall(method_pattern, context)
        if methods:
            features['key_methods'] = methods[:3]  # åªå–å‰3ä¸ªæ–¹æ³•
        
        return features
    
    def _has_feature_overlap(self, features1, features2):
        """æ£€æŸ¥ä¸¤ä¸ªé”™è¯¯ç‰¹å¾æ˜¯å¦æœ‰é‡å """
        # æ£€æŸ¥å¼‚å¸¸ç±»å‹é‡å 
        exception_overlap = set(features1['exception_types']) & set(features2['exception_types'])
        if exception_overlap:
            return True
        
        # æ£€æŸ¥é”™è¯¯æ¶ˆæ¯é‡å 
        for msg1 in features1['error_messages']:
            for msg2 in features2['error_messages']:
                if msg1 and msg2 and (msg1 in msg2 or msg2 in msg1):
                    return True
        
        # æ£€æŸ¥å…³é”®æ–¹æ³•é‡å 
        method_overlap = set(features1['key_methods']) & set(features2['key_methods'])
        if method_overlap:
            return True
        
        return False
    
    def _has_call_stack_relation(self, context1, context2):
        """æ£€æŸ¥ä¸¤ä¸ªé”™è¯¯çš„è°ƒç”¨æ ˆæ˜¯å¦æœ‰å…³è”"""
        # æå–è°ƒç”¨æ ˆä¸­çš„ç±»å’Œæ–¹æ³•
        stack_pattern = r'at ([\w\.$]+)\.'
        
        stack1 = re.findall(stack_pattern, context1)
        stack2 = re.findall(stack_pattern, context2)
        
        if not stack1 or not stack2:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…±åŒçš„è°ƒç”¨è·¯å¾„
        common_classes = set(stack1) & set(stack2)
        if len(common_classes) >= 2:  # è‡³å°‘2ä¸ªå…±åŒç±»
            return True
        
        return False
    
    def _identify_root_cause(self, error_chain):
        """ä»å¼‚å¸¸é“¾ä¸­è¯†åˆ«æ ¹æœ¬åŸå› 
        
        ç­–ç•¥ï¼š
        1. ä¼˜å…ˆé€‰æ‹©Crash/ANRï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆè¡¨ç°ï¼‰
        2. å¦‚æœæ²¡æœ‰Crash/ANRï¼Œé€‰æ‹©è°ƒç”¨æ ˆæœ€æ·±çš„é”™è¯¯
        3. å¦‚æœè°ƒç”¨æ ˆæ·±åº¦ç›¸åŒï¼Œé€‰æ‹©æ—¶é—´æœ€æ—©çš„
        """
        if not error_chain:
            return None
        
        if len(error_chain) == 1:
            return error_chain[0]
        
        # ç­–ç•¥1ï¼šä¼˜å…ˆé€‰æ‹©Crash/ANRï¼ˆå› ä¸ºå®ƒä»¬ä¿¡æ¯æœ€å®Œæ•´ï¼‰
        crash_anr = [e for e in error_chain if e['category'] in ['crash', 'anr']]
        if crash_anr:
            # å¦‚æœæœ‰å¤šä¸ªcrash/anrï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªï¼ˆæ—¶é—´æœ€æ—©ï¼‰
            return crash_anr[0]
        
        # ç­–ç•¥2ï¼šé€‰æ‹©è°ƒç”¨æ ˆæœ€æ·±çš„é”™è¯¯ï¼ˆä¿¡æ¯æœ€å®Œæ•´ï¼‰
        def get_stack_depth(error):
            context = ' '.join(error.get('context', []))
            # ç»Ÿè®¡"at "å‡ºç°æ¬¡æ•°ä½œä¸ºå †æ ˆæ·±åº¦
            return context.count(' at ')
        
        error_chain.sort(key=get_stack_depth, reverse=True)
        max_depth = get_stack_depth(error_chain[0])
        
        # æ‰¾å‡ºæ‰€æœ‰æœ€å¤§æ·±åº¦çš„é”™è¯¯
        deepest_errors = [e for e in error_chain if get_stack_depth(e) == max_depth]
        
        # ç­–ç•¥3ï¼šåœ¨æœ€æ·±çš„é”™è¯¯ä¸­é€‰æ‹©æ—¶é—´æœ€æ—©çš„
        return deepest_errors[0]
    
    def _format_iso_timestamp(self, timestamp_str):
        """å°†æ—¶é—´æˆ³æ ¼å¼åŒ–ä¸ºISO 8601æ ¼å¼"""
        if not timestamp_str:
            return datetime.now().strftime("%Y-%m-%dT%H:%M:%S.000Z")
        
        try:
            # å°è¯•è§£æç°æœ‰æ ¼å¼
            dt = datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")
            return dt.strftime("%Y-%m-%dT%H:%M:%S.000Z")
        except:
            return timestamp_str

    def _print_test_overview(self):
        """æ‰“å°æµ‹è¯•æ¦‚è§ˆ"""
        summary = self.analysis_results['test_summary']
        
        safe_print(f"\n{EMOJI['chart']} æµ‹è¯•æ¦‚è§ˆ:")
        print("  â€¢ æµ‹è¯•çŠ¶æ€: {}".format(summary.get('status', 'æœªçŸ¥')))
        if 'events_injected' in summary:
            print("  â€¢ æ³¨å…¥äº‹ä»¶æ•°: {}".format(summary['events_injected']))
        if 'abort_reason' in summary:
            print("  â€¢ ä¸­æ­¢åŸå› : {}".format(summary['abort_reason']))
        print("  â€¢ å‘ç°å´©æºƒ: {} ä¸ª".format(summary.get('total_crashes', 0)))
        print("  â€¢ å‘ç°ANR: {} ä¸ª".format(summary.get('total_anrs', 0)))
        print("  â€¢ å‘ç°å¼‚å¸¸: {} ä¸ª".format(summary.get('total_exceptions', 0)))

    def _print_crash_list(self):
        """æ‰“å°å´©æºƒé—®é¢˜åˆ—è¡¨"""
        if not self.analysis_results['crashes']:
            safe_print(f"\n{EMOJI['check']} æœªå‘ç°å´©æºƒé—®é¢˜")
            return
        
        safe_print("\n{} å´©æºƒé—®é¢˜åˆ—è¡¨ ({}ä¸ª):".format(EMOJI['red_circle'], len(self.analysis_results['crashes'])))
        print("-" * 80)
        
        for i, crash in enumerate(self.analysis_results['crashes'], 1):
            print("{}. è¿›ç¨‹: {} (PID: {})".format(i, crash['process'], crash['pid']))
            print("   â€¢ å¼‚å¸¸ç±»å‹: {}".format(crash['exception_type']))
            print("   â€¢ å‘ç”Ÿæ—¶é—´: {}".format(crash['timestamp']))
            print("   â€¢ ä¸¥é‡ç¨‹åº¦: {}".format(crash['severity']))
            
            # æ ¹å› åˆ†æ
            if crash.get('root_cause'):
                print("   â€¢ æ ¹æœ¬åŸå› åˆ†æ:")
                for cause in crash['root_cause']:
                    print("     - {} (ç½®ä¿¡åº¦: {})".format(cause['type'], cause['confidence']))
                    print("       æè¿°: {}".format(cause['description']))
                    print("       è§£å†³æ–¹æ¡ˆ: {}".format(cause['solution']))
            
            # é”™è¯¯è¯¦æƒ…æ‘˜è¦
            if crash.get('error_details'):
                error_preview = crash['error_details'][:100] + "..." if len(crash['error_details']) > 100 else crash['error_details']
                print("   â€¢ é”™è¯¯æ‘˜è¦: {}".format(error_preview))
            
            print()

    def _print_anr_list(self):
        """æ‰“å°ANRé—®é¢˜åˆ—è¡¨"""
        if not self.analysis_results['anrs']:
            safe_print(f"\n{EMOJI['check']} æœªå‘ç°ANRé—®é¢˜")
            return
        
        safe_print("\n{} ANRé—®é¢˜åˆ—è¡¨ ({}ä¸ª):".format(EMOJI['yellow_circle'], len(self.analysis_results['anrs'])))
        print("-" * 80)
        
        for i, anr in enumerate(self.analysis_results['anrs'], 1):
            print("{}. è¿›ç¨‹: {} (PID: {})".format(i, anr['process'], anr['pid']))
            print("   â€¢ å‘ç”Ÿæ—¶é—´: {}".format(anr['timestamp']))
            print("   â€¢ ä¸¥é‡ç¨‹åº¦: {}".format(anr['severity']))
            
            # æ ¹å› åˆ†æ
            if anr.get('root_cause'):
                print("   â€¢ æ ¹æœ¬åŸå› åˆ†æ:")
                for cause in anr['root_cause']:
                    print("     - {} (ç½®ä¿¡åº¦: {})".format(cause['type'], cause['confidence']))
                    print("       æè¿°: {}".format(cause['description']))
                    print("       è§£å†³æ–¹æ¡ˆ: {}".format(cause['solution']))
            
            # ä¿®å¤å»ºè®®
            if anr.get('suggestions'):
                print("   â€¢ ä¿®å¤å»ºè®®:")
                for suggestion in anr['suggestions']:
                    print("     - {}".format(suggestion))
            
            print()

    def _print_exception_list(self):
        """æ‰“å°å¼‚å¸¸é—®é¢˜åˆ—è¡¨"""
        if not self.analysis_results['exceptions']:
            safe_print(f"\n{EMOJI['check']} æœªå‘ç°å¼‚å¸¸é—®é¢˜")
            return
        
        safe_print("\n{} å¼‚å¸¸é—®é¢˜åˆ—è¡¨ ({}ä¸ª):".format(EMOJI['orange_circle'], len(self.analysis_results['exceptions'])))
        print("-" * 80)
        
        for i, exception in enumerate(self.analysis_results['exceptions'], 1):
            print("{}. è¿›ç¨‹: {}".format(i, exception['process']))
            print("   â€¢ å¼‚å¸¸ç±»å‹: {}".format(exception['root_cause']))
            print("   â€¢ å‘ç”Ÿæ—¶é—´: {}".format(exception['timestamp']))
            print("   â€¢ ä¸¥é‡ç¨‹åº¦: {}".format(exception['severity']))
            print("   â€¢ å¼‚å¸¸è¯¦æƒ…: {}".format(exception['details']))
            
            # ä¸Šä¸‹æ–‡ä¿¡æ¯
            if exception.get('context'):
                context_preview = exception['context'][:150] + "..." if len(exception['context']) > 150 else exception['context']
                print("   â€¢ ä¸Šä¸‹æ–‡: {}".format(context_preview))
            
            print()

    def _print_recommendations_summary(self):
        """æ‰“å°ä¿®å¤å»ºè®®æ€»ç»“"""
        safe_print(f"\n{EMOJI['target']} ä¿®å¤å»ºè®®æ€»ç»“:")
        safe_print("-" * 80)
        
        # å´©æºƒç›¸å…³å»ºè®®
        if self.analysis_results['crashes']:
            safe_print(f"{EMOJI['red_circle']} é’ˆå¯¹å´©æºƒé—®é¢˜çš„å»ºè®®:")
            print("  â€¢ æ£€æŸ¥ç©ºæŒ‡é’ˆå¼‚å¸¸å’Œå¯¹è±¡åˆå§‹åŒ–")
            print("  â€¢ ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œé¿å…å†…å­˜æ³„æ¼")
            print("  â€¢ éªŒè¯æƒé™å£°æ˜å’Œè¿è¡Œæ—¶è¯·æ±‚")
            print("  â€¢ æ£€æŸ¥æ•°æ®åº“æ“ä½œå’Œäº‹åŠ¡ç®¡ç†")
            print("  â€¢ æŸ¥çœ‹å®Œæ•´å †æ ˆè½¨è¿¹å®šä½é—®é¢˜ä»£ç ")
        
        # ANRç›¸å…³å»ºè®®
        if self.analysis_results['anrs']:
            safe_print(f"\n{EMOJI['yellow_circle']} é’ˆå¯¹ANRé—®é¢˜çš„å»ºè®®:")
            print("  â€¢ æ£€æŸ¥ä¸»çº¿ç¨‹ä¸­çš„è€—æ—¶æ“ä½œ")
            print("  â€¢ ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œæ–‡ä»¶IOæ“ä½œ")
            print("  â€¢ å‡å°‘ç½‘ç»œè¯·æ±‚é˜»å¡ï¼Œä½¿ç”¨å¼‚æ­¥å¤„ç†")
            print("  â€¢ ä½¿ç”¨æ€§èƒ½åˆ†æå·¥å…·æ£€æµ‹æ€§èƒ½ç“¶é¢ˆ")
            print("  â€¢ æŸ¥çœ‹/data/anr/traces.txtè·å–è¯¦ç»†å †æ ˆ")
        
        # å¼‚å¸¸ç›¸å…³å»ºè®®
        if self.analysis_results['exceptions']:
            safe_print(f"\n{EMOJI['orange_circle']} é’ˆå¯¹å¼‚å¸¸é—®é¢˜çš„å»ºè®®:")
            print("  â€¢ å®Œå–„å¼‚å¸¸å¤„ç†æœºåˆ¶")
            print("  â€¢ å¢åŠ è¾“å…¥å‚æ•°éªŒè¯")
            print("  â€¢ æ£€æŸ¥ç¬¬ä¸‰æ–¹åº“å…¼å®¹æ€§")
            print("  â€¢ æµ‹è¯•è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸åœºæ™¯")
        
        # æ€»ä½“å»ºè®®
        safe_print(f"\n{EMOJI['note']} æ€»ä½“æµ‹è¯•å»ºè®®:")
        print("  â€¢ å¢åŠ Monkeyæµ‹è¯•å¼ºåº¦å’Œè¦†ç›–èŒƒå›´")
        print("  â€¢ ç»“åˆä¸åŒå‚æ•°é…ç½®è¿›è¡Œå¤šè½®æµ‹è¯•")
        print("  â€¢ ä½¿ç”¨Logcatå’Œæ€§èƒ½å·¥å…·è¿›è¡Œç»¼åˆåˆ†æ")
        print("  â€¢ å»ºç«‹é—®é¢˜è·Ÿè¸ªå’Œå›å½’æµ‹è¯•æœºåˆ¶")

    def save_list_report(self, filename=None):
        """ä¿å­˜åˆ—è¡¨å¼æŠ¥å‘Š"""
        if filename is None:
            filename = f"monkey_list_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        original_stdout = sys.stdout
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                sys.stdout = f
                self.generate_list_style_report()
                sys.stdout = original_stdout
            
            safe_print(f"\n{EMOJI['save']} åˆ—è¡¨å¼æŠ¥å‘Šå·²ä¿å­˜è‡³: {filename}")
            return filename
        except Exception as e:
            sys.stdout = original_stdout
            safe_print(f"{EMOJI['cross']} ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
            return None
    
    def save_json_report(self, output_path=None, enable_correlation=False, simple_format=True):
        """ä¿å­˜JSONæ ¼å¼æŠ¥å‘Š
        
        Args:
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆç›®å½•æˆ–å®Œæ•´æ–‡ä»¶è·¯å¾„ï¼‰
            enable_correlation: æ˜¯å¦å¯ç”¨å…³è”åˆ†æ
            simple_format: æ˜¯å¦ä½¿ç”¨ç®€åŒ–æ ¼å¼ï¼ˆé»˜è®¤Trueï¼Œåªè¾“å‡ºåŸºæœ¬å­—æ®µï¼‰
        """
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
        
        # åˆ›å»ºä¸»è¾“å‡ºç›®å½•ï¼šreport_YYYYMMDDHHmmSS
        if output_path is None:
            # æ— å‚æ•°ï¼šåœ¨å½“å‰ç›®å½•ä¸‹åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å¤¹
            main_output_dir = f"report_{timestamp}"
        elif os.path.basename(output_path).startswith('report_'):
            # å¦‚æœæŒ‡å®šäº† report_xxx æ ¼å¼çš„ç›®å½•åï¼Œç›´æ¥ä½¿ç”¨ï¼ˆæ‰¹é‡å¤„ç†æ¨¡å¼ï¼‰
            main_output_dir = output_path
        elif os.path.isdir(output_path) or output_path.endswith(os.sep):
            # å¦‚æœæ˜¯ç›®å½•ï¼šåœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å¤¹
            base_dir = output_path.rstrip(os.sep)
            main_output_dir = os.path.join(base_dir, f"report_{timestamp}")
        else:
            # å¦‚æœæŒ‡å®šäº†æ–‡ä»¶åï¼Œæå–ç›®å½•éƒ¨åˆ†
            output_dir = os.path.dirname(output_path)
            if output_dir:
                main_output_dir = os.path.join(output_dir, f"report_{timestamp}")
            else:
                main_output_dir = f"report_{timestamp}"
        
        # åˆ›å»ºä¸»ç›®å½•å’Œå­ç›®å½•
        json_dir = os.path.join(main_output_dir, "json")
        html_dir = os.path.join(main_output_dir, "html")
        os.makedirs(json_dir, exist_ok=True)
        os.makedirs(html_dir, exist_ok=True)
        
        # ç”ŸæˆJSONæ–‡ä»¶å
        default_filename = f"report_{timestamp}.json"
        filename = os.path.join(json_dir, default_filename)
        
        safe_print(f"\n{EMOJI['folder']} åˆ›å»ºè¾“å‡ºç›®å½•: {main_output_dir}")
        safe_print(f"   â”œâ”€â”€ json/  (JSONæ–‡ä»¶)")
        safe_print(f"   â””â”€â”€ html/  (HTMLæ–‡ä»¶)")
        
        try:
            # ç”Ÿæˆé”™è¯¯æŠ¥å‘Š
            json_data = self.generate_json_report(enable_correlation)
            
            if simple_format:
                # ç®€åŒ–æ ¼å¼ï¼šæ¯ä¸ªé”™è¯¯ç”Ÿæˆä¸€ä¸ªç‹¬ç«‹çš„JSONæ–‡ä»¶
                saved_files = []
                
                if json_data:
                    # æœ‰é”™è¯¯æ—¶ç”ŸæˆJSONæ–‡ä»¶
                    safe_print(f"\n{EMOJI['save']} æ­£åœ¨ç”ŸæˆJSONæŠ¥å‘Š...")
                    
                    for idx, error in enumerate(json_data):
                        # ä¸ºæ¯ä¸ªé”™è¯¯ç”Ÿæˆç‹¬ç«‹çš„JSONå¯¹è±¡ï¼ˆä¸æ˜¯æ•°ç»„ï¼‰
                        simple_error = {
                            'category': error['category'],
                            'processName': error['processName'],
                            'timestamp': error['timestamp'],
                            'context': error['context']
                        }
                        # æ³¨æ„ï¼šä¸åŒ…å«pidå­—æ®µï¼Œä¸ç›®æ ‡æ ¼å¼ä¸€è‡´
                        
                        # ç”Ÿæˆæ–‡ä»¶åï¼šreport_YYYYMMDDHHmmSS_N.json
                        if len(json_data) == 1:
                            # åªæœ‰ä¸€ä¸ªé”™è¯¯ï¼Œä¸åŠ åºå·
                            error_filename = os.path.join(json_dir, f"report_{timestamp}.json")
                        else:
                            # å¤šä¸ªé”™è¯¯ï¼Œæ·»åŠ åºå·
                            error_filename = os.path.join(json_dir, f"report_{timestamp}_{idx+1}.json")
                        
                        # ä¿å­˜å•ä¸ªé”™è¯¯å¯¹è±¡
                        with open(error_filename, 'w', encoding='utf-8') as f:
                            json.dump(simple_error, f, ensure_ascii=False, indent=2)
                        
                        saved_files.append(error_filename)
                    
                    safe_print(f"   {EMOJI['check']} å·²ç”Ÿæˆ {len(saved_files)} ä¸ªJSONæ–‡ä»¶")
                    if enable_correlation:
                        safe_print(f"   {EMOJI['check']} å·²å¯ç”¨å…³è”åˆ†æï¼Œè¿‡æ»¤è¡ç”Ÿé”™è¯¯")
                    safe_print(f"   {EMOJI['note']} ä½¿ç”¨ç®€åŒ–æ ¼å¼ï¼ˆä»…åŸºæœ¬å­—æ®µï¼‰")
                    safe_print(f"   {EMOJI['file']} JSONæ–‡ä»¶ä¿å­˜åœ¨: {json_dir}")
                    
                    # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
                    for i, file in enumerate(saved_files, 1):
                        rel_path = os.path.relpath(file, main_output_dir)
                        print(f"      {i}. {rel_path}")
                    
                    # å¯¹æ¯ä¸ªJSONæ–‡ä»¶è°ƒç”¨ report.py
                    for error_file in saved_files:
                        self._call_report_py(error_file, html_dir, timestamp, len(saved_files))
                else:
                    # æ²¡æœ‰é”™è¯¯
                    safe_print(f"\n{EMOJI['check']} æœªå‘ç°é”™è¯¯")
                    safe_print(f"   {EMOJI['note']} æµ‹è¯•é€šè¿‡ï¼Œæ— crashã€ANRæˆ–å¼‚å¸¸")
                
                # æ€»æ˜¯è°ƒç”¨ summarize_reports.py ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
                # æœ‰é”™è¯¯æ—¶ç”Ÿæˆè¯¦ç»†æ±‡æ€»ï¼Œæ— é”™è¯¯æ—¶ç”Ÿæˆ"æµ‹è¯•æˆåŠŸ"æŠ¥å‘Š
                self._call_summarize_reports()
                
                # è¿”å›ä¸»è¾“å‡ºç›®å½•ï¼ˆå‘åå…¼å®¹ï¼‰
                filename = main_output_dir
            else:
                # å®Œæ•´æ ¼å¼ï¼šåŒ…å«æ‰€æœ‰å¢å¼ºä¿¡æ¯ï¼ˆä¿å­˜ä¸ºå•ä¸ªæ–‡ä»¶ï¼‰
                
                if json_data:
                    # æœ‰é”™è¯¯æ—¶ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
                    log_text = "".join(self.monkey_log)
                    environment = self.extract_environment_context(log_text)
                    
                    full_report = {
                        'meta': {
                            'generated_at': datetime.now().isoformat(),
                            'analyzer_version': '2.0-enhanced',
                            'total_errors': len(json_data),
                            'correlation_enabled': enable_correlation
                        },
                        'environment': environment,
                        'errors': json_data,
                        'summary': {
                            'by_priority': self._count_by_priority(json_data),
                            'by_category': self._count_by_category(json_data),
                            'stability_score': self._calculate_stability_score(json_data)
                        }
                    }
                    
                    # ä¿å­˜åˆ°jsonç›®å½•
                    full_json_file = os.path.join(json_dir, f"report_{timestamp}_full.json")
                    with open(full_json_file, 'w', encoding='utf-8') as f:
                        json.dump(full_report, f, ensure_ascii=False, indent=2)
                    
                    safe_print(f"\n{EMOJI['save']} JSONæ ¼å¼æŠ¥å‘Šå·²ä¿å­˜è‡³: {full_json_file}")
                    safe_print(f"   å…±{len(json_data)}ä¸ªç‹¬ç‰¹é”™è¯¯")
                    if enable_correlation:
                        safe_print(f"   {EMOJI['check']} å·²å¯ç”¨å…³è”åˆ†æï¼Œè¿‡æ»¤è¡ç”Ÿé”™è¯¯")
                    safe_print(f"   {EMOJI['chart']} ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼ˆåŒ…å«å¢å¼ºä¿¡æ¯ï¼‰")
                    safe_print(f"   {EMOJI['file']} JSONæ–‡ä»¶ä¿å­˜åœ¨: {json_dir}")
                    
                    # ç”Ÿæˆå¹¶ä¿å­˜æ–‡æœ¬æ€»ç»“åˆ°ä¸»ç›®å½•
                    summary_filename = os.path.join(main_output_dir, f"report_{timestamp}_summary.txt")
                    summary_text = self.generate_executive_summary(json_data, environment)
                    with open(summary_filename, 'w', encoding='utf-8') as f:
                        f.write(summary_text)
                    safe_print(f"   {EMOJI['note']} æ‰§è¡Œæ‘˜è¦å·²ä¿å­˜è‡³: {os.path.relpath(summary_filename, main_output_dir)}")
                    
                    # å®Œæ•´æ ¼å¼è°ƒç”¨ report.py
                    self._call_report_py(full_json_file, html_dir, timestamp, 1)
                else:
                    # æ²¡æœ‰é”™è¯¯
                    safe_print(f"\n{EMOJI['check']} æœªå‘ç°é”™è¯¯")
                    safe_print(f"   {EMOJI['note']} æµ‹è¯•é€šè¿‡ï¼Œæ— crashã€ANRæˆ–å¼‚å¸¸")
                
                # æ€»æ˜¯ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šï¼ˆæœ‰é”™è¯¯æ—¶è¯¦ç»†æ±‡æ€»ï¼Œæ— é”™è¯¯æ—¶"æµ‹è¯•æˆåŠŸ"ï¼‰
                self._call_summarize_reports()
                
                # è¿”å›ä¸»è¾“å‡ºç›®å½•
                filename = main_output_dir
            
            return filename
        except Exception as e:
            safe_print(f"{EMOJI['cross']} ä¿å­˜JSONæŠ¥å‘Šå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _call_report_py(self, json_filename, html_dir=None, timestamp=None, total_files=1):
        """è°ƒç”¨ report.py ç”ŸæˆæŠ¥å‘Š
        
        Args:
            json_filename: JSONæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼‰
            html_dir: HTMLæ–‡ä»¶è¾“å‡ºç›®å½•
            timestamp: æ—¶é—´æˆ³
            total_files: æ€»æ–‡ä»¶æ•°
        """
        try:
            # æ£€æŸ¥ report.py æ˜¯å¦å­˜åœ¨
            script_dir = os.path.dirname(os.path.abspath(__file__))
            report_script = os.path.join(script_dir, 'report.py')
            
            if not os.path.exists(report_script):
                # å¦‚æœå½“å‰ç›®å½•æ²¡æœ‰ï¼Œå°è¯•å½“å‰å·¥ä½œç›®å½•
                report_script = 'report.py'
                if not os.path.exists(report_script):
                    if total_files == 1:
                        safe_print(f"\n{EMOJI['warning']}  æœªæ‰¾åˆ° report.pyï¼Œè·³è¿‡æŠ¥å‘Šç”Ÿæˆ")
                    return
            
            # æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
            json_basename = os.path.basename(json_filename)
            if total_files > 1:
                safe_print(f"\n{EMOJI['process']} æ­£åœ¨å¤„ç†: {json_basename}")
            else:
                safe_print(f"\n{EMOJI['process']} æ­£åœ¨è°ƒç”¨ report.py ç”ŸæˆæŠ¥å‘Š...")
            
            # è½¬æ¢JSONæ–‡ä»¶ä¸ºç»å¯¹è·¯å¾„
            json_abs_path = os.path.abspath(json_filename)
            
            # è°ƒç”¨ report.py
            cmd_args = ['python', report_script, json_abs_path]
            
            # å¦‚æœæœ‰ logcat ç›®å½•è·¯å¾„ï¼Œæ·»åŠ  --logpath å‚æ•°
            if self.logcat_dir_path:
                cmd_args.extend(['--log-path', self.logcat_dir_path])
            
            # æ‰“å°å®Œæ•´çš„è°ƒç”¨å‘½ä»¤
            cmd_str = ' '.join(cmd_args)
            if total_files > 1:
                safe_print(f"   {EMOJI['note']} è°ƒç”¨report: {cmd_str}")
            else:
                safe_print(f"{EMOJI['note']} è°ƒç”¨report: {cmd_str}")
            
            # å¦‚æœæŒ‡å®šäº†html_dirï¼Œåœ¨è¯¥ç›®å½•ä¸­æ‰§è¡Œï¼›å¦åˆ™åœ¨å½“å‰ç›®å½•æ‰§è¡Œ
            cwd = html_dir if html_dir and os.path.exists(html_dir) else None
            
            result = subprocess.run(
                cmd_args,
                capture_output=True,
                text=True,
                timeout=30,  # 30ç§’è¶…æ—¶
                cwd=cwd  # åœ¨htmlç›®å½•ä¸­æ‰§è¡Œ
            )
            
            if result.returncode == 0:
                if total_files > 1:
                    safe_print(f"   {EMOJI['check']} å¤„ç†å®Œæˆ")
                else:
                    safe_print(f"{EMOJI['check']} report.py æ‰§è¡ŒæˆåŠŸ")
                # æ‰“å° report.py çš„è¾“å‡º
                if result.stdout:
                    # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œç¼©è¿›è¾“å‡º
                    if total_files > 1:
                        for line in result.stdout.strip().split('\n'):
                            safe_print(f"   {line}")
                    else:
                        safe_print(result.stdout)
            else:
                safe_print(f"{EMOJI['cross']} report.py æ‰§è¡Œå¤±è´¥ (é€€å‡ºç : {result.returncode})")
                if result.stderr:
                    safe_print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
                    
        except subprocess.TimeoutExpired:
            safe_print(f"{EMOJI['clock']}  report.py æ‰§è¡Œè¶…æ—¶ï¼ˆ>30ç§’ï¼‰")
        except FileNotFoundError:
            safe_print(f"{EMOJI['warning']}  æœªæ‰¾åˆ° Python è§£é‡Šå™¨æˆ– report.py")
        except Exception as e:
            safe_print(f"{EMOJI['warning']}  è°ƒç”¨ report.py æ—¶å‡ºé”™: {e}")
    
    def _call_summarize_reports(self):
        """è°ƒç”¨ summarize_reports.py ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        
        summarize_reports.py ä¼šè‡ªåŠ¨ä» output ç›®å½•è¯»å–HTMLæ–‡ä»¶å¹¶ç”Ÿæˆæ±‡æ€»
        """
        try:
            # æ£€æŸ¥ summarize_reports.py æ˜¯å¦å­˜åœ¨
            script_dir = os.path.dirname(os.path.abspath(__file__))
            summarize_script = os.path.join(script_dir, 'summarize_reports.py')
            
            if not os.path.exists(summarize_script):
                # å¦‚æœå½“å‰ç›®å½•æ²¡æœ‰ï¼Œå°è¯•å½“å‰å·¥ä½œç›®å½•
                summarize_script = 'summarize_reports.py'
                if not os.path.exists(summarize_script):
                    safe_print(f"\n{EMOJI['warning']}  æœªæ‰¾åˆ° summarize_reports.pyï¼Œè·³è¿‡æ±‡æ€»æŠ¥å‘Šç”Ÿæˆ")
                    return
            
            safe_print(f"\n{EMOJI['chart']} æ­£åœ¨ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
            
            # ç›´æ¥è°ƒç”¨ summarize_reports.pyï¼ˆä¸éœ€è¦å‚æ•°ï¼‰
            cmd_args = ['python', summarize_script]
            
            # æ‰“å°å®Œæ•´çš„è°ƒç”¨å‘½ä»¤
            cmd_str = ' '.join(cmd_args)
            safe_print(f"{EMOJI['note']} è°ƒç”¨summarize_report: {cmd_str}")
            
            result = subprocess.run(
                cmd_args,
                capture_output=True,
                text=True,
                timeout=60  # 60ç§’è¶…æ—¶
            )
            
            if result.returncode == 0:
                safe_print(f"{EMOJI['check']} æ±‡æ€»æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
                # æ‰“å°è¾“å‡º
                if result.stdout:
                    for line in result.stdout.strip().split('\n'):
                        safe_print(f"   {line}")
            else:
                safe_print(f"{EMOJI['cross']} summarize_reports.py æ‰§è¡Œå¤±è´¥ (é€€å‡ºç : {result.returncode})")
                if result.stderr:
                    safe_print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
                    
        except subprocess.TimeoutExpired:
            safe_print(f"{EMOJI['clock']}  summarize_reports.py æ‰§è¡Œè¶…æ—¶ï¼ˆ>60ç§’ï¼‰")
        except FileNotFoundError:
            safe_print(f"{EMOJI['warning']}  æœªæ‰¾åˆ° Python è§£é‡Šå™¨æˆ– summarize_reports.py")
        except Exception as e:
            safe_print(f"{EMOJI['warning']}  è°ƒç”¨ summarize_reports.py æ—¶å‡ºé”™: {e}")
    
    def _count_by_category(self, errors):
        """æŒ‰ç±»åˆ«ç»Ÿè®¡"""
        counts = defaultdict(int)
        for error in errors:
            counts[error['category']] += 1
        return dict(counts)
    
    def print_json_report(self, enable_correlation=False):
        """æ‰“å°JSONæ ¼å¼æŠ¥å‘Šåˆ°æ§åˆ¶å°ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            enable_correlation: æ˜¯å¦å¯ç”¨å…³è”åˆ†æ
        """
        # ç”Ÿæˆé”™è¯¯æŠ¥å‘Š
        json_data = self.generate_json_report(enable_correlation)
        
        # æå–ç¯å¢ƒä¸Šä¸‹æ–‡
        log_text = "".join(self.monkey_log)
        environment = self.extract_environment_context(log_text)
        
        # é¦–å…ˆæ‰“å°æ‰§è¡Œæ‘˜è¦
        summary_text = self.generate_executive_summary(json_data, environment)
        safe_print(summary_text)
        
        # ç„¶åæ‰“å°è¯¦ç»†JSONæŠ¥å‘Š
        safe_print("\n" + "="*80)
        safe_print(f"{EMOJI['clipboard']} MONKEYæµ‹è¯•è¯¦ç»†æŠ¥å‘Š - JSONæ ¼å¼")
        if enable_correlation:
            safe_print("ã€å…³è”åˆ†ææ¨¡å¼ï¼šä»…æ˜¾ç¤ºæ ¸å¿ƒé”™è¯¯ã€‘")
        safe_print("="*80)
        
        # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯çš„è¯¦æƒ…ï¼ˆé¿å…è¾“å‡ºè¿‡é•¿ï¼‰
        display_errors = json_data[:10]
        for i, error in enumerate(display_errors, 1):
            safe_print(f"\n--- é”™è¯¯ #{i} ---")
            safe_print(json.dumps(error, ensure_ascii=False, indent=2))
        
        if len(json_data) > 10:
            safe_print(f"\n... è¿˜æœ‰ {len(json_data) - 10} ä¸ªé”™è¯¯æœªæ˜¾ç¤º ...")
        
        safe_print("\n" + "="*80)
        safe_print(f"æ€»è®¡: {len(json_data)} ä¸ªç‹¬ç‰¹é”™è¯¯")
        if enable_correlation:
            safe_print("ï¼ˆå·²è¿‡æ»¤è¡ç”Ÿé”™è¯¯ï¼Œä»…æ˜¾ç¤ºæ ¹æœ¬åŸå› ï¼‰")
        safe_print(f"{EMOJI['target']} æç¤º: å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°æ–‡ä»¶")
        safe_print("="*80)

def find_monkey_logs_folders(base_dir='.'):
    """æŸ¥æ‰¾å½“å‰ç›®å½•ä¸‹æ‰€æœ‰çš„ monkey_logs_* æ–‡ä»¶å¤¹
    
    è¿”å›ï¼š[(folder_path, log_file_path, timestamp), ...]
    """
    monkey_folders = []
    
    try:
        # éå†å½“å‰ç›®å½•
        for item in os.listdir(base_dir):
            item_path = os.path.join(base_dir, item)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ monkey_logs_* æ–‡ä»¶å¤¹
            if os.path.isdir(item_path) and item.startswith('monkey_logs_'):
                # æå–æ—¶é—´æˆ³
                timestamp = item.replace('monkey_logs_', '')
                
                # æŸ¥æ‰¾è¯¥æ–‡ä»¶å¤¹ä¸­çš„ .log æ–‡ä»¶
                log_files = [f for f in os.listdir(item_path) if f.endswith('.log')]
                
                if log_files:
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„ .log æ–‡ä»¶
                    log_file = os.path.join(item_path, log_files[0])
                    monkey_folders.append((item_path, log_file, timestamp))
        
        # æŒ‰æ—¶é—´æˆ³æ’åº
        monkey_folders.sort(key=lambda x: x[2])
        
    except Exception as e:
        safe_print(f"{EMOJI['warning']} æ‰«æç›®å½•æ—¶å‡ºé”™: {e}")
    
    return monkey_folders


def batch_process_monkey_logs(package=None, enable_correlation=True, simple_format=True):
    """æ‰¹é‡å¤„ç†å½“å‰ç›®å½•ä¸‹æ‰€æœ‰çš„ monkey_logs_* æ–‡ä»¶å¤¹"""
    
    safe_print(f"{EMOJI['search']} Monkeyæ—¥å¿—æ‰¹é‡åˆ†æå·¥å…·")
    safe_print("=" * 80)
    
    # æŸ¥æ‰¾æ‰€æœ‰ monkey_logs_* æ–‡ä»¶å¤¹
    safe_print(f"\n{EMOJI['dir']} æ­£åœ¨æ‰«æå½“å‰ç›®å½•...")
    monkey_folders = find_monkey_logs_folders()
    
    if not monkey_folders:
        safe_print(f"{EMOJI['warning']} å½“å‰ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° monkey_logs_* æ–‡ä»¶å¤¹")
        return
    
    safe_print(f"{EMOJI['check']} æ‰¾åˆ° {len(monkey_folders)} ä¸ª monkey_logs æ–‡ä»¶å¤¹\n")
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶å¤¹
    success_count = 0
    fail_count = 0
    
    for idx, (folder_path, log_file, timestamp) in enumerate(monkey_folders, 1):
        safe_print(f"\n{'=' * 80}")
        safe_print(f"{EMOJI['proc']} [{idx}/{len(monkey_folders)}] å¤„ç†: {os.path.basename(folder_path)}")
        safe_print(f"{EMOJI['file']} æ—¥å¿—æ–‡ä»¶: {os.path.basename(log_file)}")
        safe_print("=" * 80)
        
        try:
            # åˆ›å»ºåˆ†æå™¨
            analyzer = ListStyleMonkeyAnalyzer(target_package=package)
            
            # åŠ è½½æ—¥å¿—æ–‡ä»¶
            if not analyzer.load_monkey_log(log_file):
                safe_print(f"{EMOJI['cross']} åŠ è½½æ—¥å¿—å¤±è´¥ï¼Œè·³è¿‡")
                fail_count += 1
                continue
            
            # æ‰§è¡Œåˆ†æ
            analyzer.analyze_monkey_log(output_format='json', 
                                       enable_correlation=enable_correlation)
            
            # ç”ŸæˆæŠ¥å‘Šåç§°ï¼ˆå¯¹åº” monkey_logs_xxx -> report_xxxï¼Œä½¿ç”¨ç›¸åŒçš„æ—¶é—´æˆ³ï¼‰
            report_dir_name = f"report_{timestamp}"
            
            # ä¿å­˜æŠ¥å‘Šï¼ˆæŒ‡å®šè¾“å‡ºç›®å½•ï¼Œä½¿ç”¨ä¸ monkey_logs ç›¸åŒçš„æ—¶é—´æˆ³ï¼‰
            report_file = analyzer.save_json_report(
                output_path=report_dir_name,  # ä½¿ç”¨ä¸ monkey_logs_xxx å¯¹åº”çš„ report_xxx
                enable_correlation=enable_correlation,
                simple_format=simple_format
            )
            
            if report_file:
                safe_print(f"\n{EMOJI['check']} åˆ†æå®Œæˆï¼æŠ¥å‘Šç›®å½•: {os.path.dirname(report_file)}")
                success_count += 1
            else:
                safe_print(f"\n{EMOJI['cross']} æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
                fail_count += 1
                
        except Exception as e:
            safe_print(f"\n{EMOJI['cross']} å¤„ç†å¤±è´¥: {e}")
            fail_count += 1
    
    # æ‰“å°æ€»ç»“
    safe_print(f"\n{'=' * 80}")
    safe_print(f"{EMOJI['chart']} æ‰¹é‡å¤„ç†å®Œæˆ")
    safe_print("=" * 80)
    safe_print(f"  {EMOJI['check']} æˆåŠŸ: {success_count} ä¸ª")
    if fail_count > 0:
        safe_print(f"  {EMOJI['cross']} å¤±è´¥: {fail_count} ä¸ª")
    safe_print(f"  {EMOJI['note']} æ€»è®¡: {len(monkey_folders)} ä¸ª")


def main():
    parser = argparse.ArgumentParser(
        description='Monkeyæ—¥å¿—åˆ†æå·¥å…· - é»˜è®¤æ‰¹é‡å¤„ç†å½“å‰ç›®å½•ä¸‹æ‰€æœ‰ monkey_logs_* æ–‡ä»¶å¤¹',
        epilog='ç¤ºä¾‹:\n'
               '  æ‰¹é‡å¤„ç†ï¼ˆé»˜è®¤ï¼‰: python analyze.py\n'
               '  å•æ–‡ä»¶å¤„ç†: python analyze.py monkey_log.txt'
    )
    parser.add_argument('monkey_log', nargs='?', help='Monkeyæµ‹è¯•æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼ŒæŒ‡å®šåˆ™è¿›å…¥å•æ–‡ä»¶æ¨¡å¼ï¼‰')
    parser.add_argument('--package', '-p', help='ç›®æ ‡åº”ç”¨åŒ…å')
    parser.add_argument('--output', '-o', 
                        help='[å•æ–‡ä»¶æ¨¡å¼] è¾“å‡ºè·¯å¾„ï¼šå¯ä»¥æ˜¯ç›®å½•ï¼ˆä¿å­˜ä¸ºreport_æ—¶é—´æˆ³.jsonï¼‰æˆ–å®Œæ•´æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--all', '-a', action='store_true', 
                        help='æ˜¾ç¤ºæ‰€æœ‰é”™è¯¯ï¼Œä¸è¿›è¡Œå…³è”åˆ†æè¿‡æ»¤ï¼ˆé»˜è®¤åªæ˜¾ç¤ºæ ¸å¿ƒé”™è¯¯ï¼‰')
    parser.add_argument('--full', '-f', action='store_true',
                        help='è¾“å‡ºå®Œæ•´æ ¼å¼JSONï¼ˆåŒ…å«å¢å¼ºä¿¡æ¯ï¼‰ï¼Œé»˜è®¤ä¸ºç®€åŒ–æ ¼å¼')
    
    args = parser.parse_args()
    
    # é»˜è®¤å¯ç”¨å…³è”åˆ†æå’Œç®€åŒ–æ ¼å¼
    enable_correlation = not args.all
    simple_format = not args.full
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥å¿—æ–‡ä»¶ï¼Œé»˜è®¤è¿›å…¥æ‰¹é‡å¤„ç†æ¨¡å¼
    if not args.monkey_log:
        # æ‰¹é‡å¤„ç†æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
        batch_process_monkey_logs(
            package=args.package,
            enable_correlation=enable_correlation,
            simple_format=simple_format
        )
        return
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = ListStyleMonkeyAnalyzer(target_package=args.package)
    
    # é»˜è®¤å¯ç”¨å…³è”åˆ†æï¼Œé™¤éæŒ‡å®š --all
    enable_correlation = not args.all
    
    # é»˜è®¤ä½¿ç”¨ç®€åŒ–æ ¼å¼ï¼Œé™¤éæŒ‡å®š --full
    simple_format = not args.full
    
    format_type = 'JSONæ ¼å¼'
    if simple_format:
        format_type += ' (ç®€åŒ–)'
    else:
        format_type += ' (å®Œæ•´)'
    
    if enable_correlation:
        format_type += ' - å…³è”åˆ†æ'
    else:
        format_type += ' - æ‰€æœ‰é”™è¯¯'
    
    safe_print(f"{EMOJI['search']} Monkeyæ—¥å¿—åˆ†æå·¥å…· - {format_type}")
    safe_print("=" * 80)
    
    # åŠ è½½æ—¥å¿—æ–‡ä»¶
    if not analyzer.load_monkey_log(args.monkey_log):
        sys.exit(1)
    
    # æ‰§è¡Œåˆ†æï¼ˆé»˜è®¤JSONæ ¼å¼ + å…³è”åˆ†æï¼‰
    analyzer.analyze_monkey_log(output_format='json', 
                                enable_correlation=enable_correlation)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = analyzer.save_json_report(output_path=args.output, 
                                           enable_correlation=enable_correlation,
                                           simple_format=simple_format)
    
    safe_print(f"\n{EMOJI['check']} åˆ†æå®Œæˆï¼")
    if report_file:
        safe_print(f"{EMOJI['note']} æŠ¥å‘Šæ–‡ä»¶: {report_file}")
    
    # æç¤ºä¿¡æ¯
    # if enable_correlation:
    #     safe_print(f"\n{EMOJI['target']} æç¤º: ä½¿ç”¨ --all å‚æ•°å¯æŸ¥çœ‹æ‰€æœ‰é”™è¯¯ï¼ˆåŒ…æ‹¬è¡ç”Ÿé”™è¯¯ï¼‰")
    # if simple_format:
    #     safe_print(f"{EMOJI['target']} æç¤º: ä½¿ç”¨ --full å‚æ•°å¯è¾“å‡ºå®Œæ•´æ ¼å¼ï¼ˆåŒ…å«å¢å¼ºåˆ†æä¿¡æ¯ï¼‰")

if __name__ == "__main__":
    main()


# ========================================
# Monkeyæ—¥å¿—åˆ†æå·¥å…· - ä½¿ç”¨ç¤ºä¾‹
# ========================================
#
# åŸºæœ¬ç”¨æ³•ï¼ˆé»˜è®¤ï¼šç®€åŒ–JSON + å…³è”åˆ†æï¼‰ï¼š
# python analyze.py monkey_log.txt
# è¾“å‡ºç›®å½•ç»“æ„:
#   report_YYYYMMDDHHmmSS/
#   â”œâ”€â”€ json/
#   â”‚   â”œâ”€â”€ report_YYYYMMDDHHmmSS_1.json
#   â”‚   â”œâ”€â”€ report_YYYYMMDDHHmmSS_2.json
#   â”‚   â””â”€â”€ ...
#   â””â”€â”€ html/
#       â””â”€â”€ (report.pyç”Ÿæˆçš„HTMLæ–‡ä»¶)
# è‡ªåŠ¨è°ƒç”¨: python report.py report_YYYYMMDDHHmmSS_1.json (å¯¹æ¯ä¸ªæ–‡ä»¶)
#
# ä¿å­˜åˆ°æŒ‡å®šç›®å½•ï¼š
# python analyze.py monkey_log.txt --output ./reports/
# è¾“å‡º: ./reports/report_YYYYMMDDHHmmSS/json/*.json
#
# æŒ‡å®šå®Œæ•´æ–‡ä»¶è·¯å¾„ï¼š
# python analyze.py monkey_log.txt --output ./output/custom_name.json
# è¾“å‡º: ./output/report_YYYYMMDDHHmmSS/json/custom_name_1.json, ...
#
# æŒ‡å®šç›®æ ‡åº”ç”¨åŒ…åï¼š
# python analyze.py monkey_log.txt --package com.example.app
#
# æ˜¾ç¤ºæ‰€æœ‰é”™è¯¯ï¼ˆä¸è¿‡æ»¤è¡ç”Ÿé”™è¯¯ï¼‰ï¼š
# python analyze.py monkey_log.txt --all
#
# è¾“å‡ºå®Œæ•´æ ¼å¼ï¼ˆåŒ…å«å¢å¼ºåˆ†æä¿¡æ¯ï¼Œå•ä¸ªæ–‡ä»¶ï¼‰ï¼š
# python analyze.py monkey_log.txt --full
# è¾“å‡º: report_YYYYMMDDHHmmSS/json/report_YYYYMMDDHHmmSS_full.json
#
# ç»„åˆä½¿ç”¨ï¼š
# python analyze.py monkey_log.txt --all -o ./reports/
#
# ========================================
# ç›®å½•ç»“æ„è¯´æ˜
# ========================================
#
# é»˜è®¤åœ¨å½“å‰è·¯å¾„ä¸‹åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å¤¹ï¼š
# report_YYYYMMDDHHmmSS/
# â”œâ”€â”€ json/          # JSONæ–‡ä»¶ç›®å½•
# â”‚   â”œâ”€â”€ report_YYYYMMDDHHmmSS_1.json  # ç¬¬1ä¸ªé”™è¯¯
# â”‚   â”œâ”€â”€ report_YYYYMMDDHHmmSS_2.json  # ç¬¬2ä¸ªé”™è¯¯
# â”‚   â””â”€â”€ ...
# â”œâ”€â”€ html/          # HTMLæ–‡ä»¶ç›®å½•ï¼ˆç”±report.pyç”Ÿæˆï¼‰
# â”‚   â””â”€â”€ ...
# â””â”€â”€ report_YYYYMMDDHHmmSS_summary.txt  # æ‰§è¡Œæ‘˜è¦ï¼ˆ--fullæ—¶ç”Ÿæˆï¼‰
#
# æ³¨æ„ï¼šç”ŸæˆJSONåä¼šè‡ªåŠ¨è°ƒç”¨ report.py è¿›è¡Œåç»­å¤„ç†
# å¦‚æœ report.py ä¸å­˜åœ¨ï¼Œä¼šè·³è¿‡è¯¥æ­¥éª¤å¹¶ç»™å‡ºæç¤º
#
# ========================================
# è¾“å‡ºæ ¼å¼è¯´æ˜
# ========================================
#
# ç®€åŒ–æ ¼å¼ï¼ˆé»˜è®¤ï¼‰- å…¼å®¹log_s1.txtæ ¼å¼ï¼š
# [
#   {
#     "category": "crash",
#     "processName": "com.example.app",
#     "pid": "12345",
#     "timestamp": "2025-11-29T10:00:00.000Z",
#     "context": ["å †æ ˆä¿¡æ¯..."]
#   }
# ]
#
# å®Œæ•´æ ¼å¼ï¼ˆ--fullï¼‰- åŒ…å«å¢å¼ºä¿¡æ¯ï¼š
# {
#   "meta": {...},
#   "environment": {...},
#   "errors": [
#     {
#       ...åŸºæœ¬å­—æ®µ...,
#       "deduplication": {...},
#       "severity": {...},
#       "rootCause": {...}
#     }
#   ],
#   "summary": {...}
# }
#
# ========================================
# åŠŸèƒ½è¯´æ˜
# ========================================
# 
# é»˜è®¤è¡Œä¸ºï¼š
# 1. è¾“å‡ºç®€åŒ–JSONæ ¼å¼ï¼ˆåªåŒ…å«åŸºæœ¬å­—æ®µï¼‰
# 2. å¯ç”¨å¤šå¼‚å¸¸é“¾æ ¹å› åˆ†æ
# 3. è‡ªåŠ¨è¿‡æ»¤è¡ç”Ÿé”™è¯¯ï¼Œä»…æ˜¾ç¤ºæ ¸å¿ƒé”™è¯¯
# 4. è‡ªåŠ¨è¿‡æ»¤Monkeyå·¥å…·è‡ªèº«çš„é”™è¯¯ï¼ˆå¦‚flipjava.ioï¼‰
#
# å…³è”åˆ†æç­–ç•¥ï¼š
# 1. æ—¶é—´é¡ºåºåˆ†æ - ç¬¬ä¸€ä¸ªå‘ç”Ÿçš„å¼‚å¸¸é€šå¸¸æ˜¯æ ¹æœ¬åŸå› 
# 2. è°ƒç”¨é“¾åˆ†æ - åˆ†æå †æ ˆçš„è°ƒç”¨å…³ç³»
# 3. å› æœå…³ç³»è¯†åˆ« - è¯†åˆ«å¼‚å¸¸ä¹‹é—´çš„ç›´æ¥å› æœå…³ç³»
# 4. ä¸Šä¸‹æ–‡å…³è” - ç»“åˆæ—¥å¿—ä¸Šä¸‹æ–‡åˆ¤æ–­å¼‚å¸¸ç›¸å…³æ€§
# ========================================